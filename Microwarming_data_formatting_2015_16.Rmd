---
title: "Microwarming_data_formatting"
author: "Lydia Vaughn"
date: "22/05/2018"
output: html_document
---
#Description
```
This script reformats and processes data saved in line 249 of the "Barrow Data" script.  Processing includes outlier detection and recoding data with associated plot numbers.  The data originate from an field soil warming experiment in Barrow, Alaska.

Notes on column headers:
Uavg = the average of the regulator probes (regStat = "R") in the unheated plots (heatStat = "U") between depths of 10 and 25 cm (depth = c(10, 15, 20, 25))
```
#Code

##Install required packages

These packages only need to be installed once, then this code can be commented out or deleted.

Often, knitr does not like to install from the command window. If this is the case, look to the bottom right window and click on Packages -> Install -> and search for `knitr` in the window that opens.  

Knitr will provide a row of buttons across the top of the top left window in RStudio which allow you to view this document in html format (by clicking on the "Knit HTML" button), as well as run some or all of the code chunks below (by clicking on the "Chunks" button)

```{r}
#uncomment to install packages from command line
#install.packages("knitr")
#install.packages("zoo")
#install.packages("tidyverse")
#install.packages("lubridate")
```

####Read in files
```{r}
#missing some data:
long <- read.csv('data/2015_organized/longBarrowFile_2015.csv', stringsAsFactors=F) 

#complete 2016 dataset:
#long <- read.csv('data/2016_organized/longBarrowFile_2016_4.csv', stringsAsFactors=F) 

#comment/uncomment to change for 2015 vs. 2016 data

decoder <- read.csv('data/control_box_decoder.csv', stringsAsFactors=F)

heatstat <- read.csv('data/HeaterStatus.csv', stringsAsFactors=F)
```

####Packages
```{r}
library(tidyverse)
library(lubridate)
library(zoo)
```

####QA/QC full dataset
```{r}
unique(long$id)
#Drop the row if:

#1) If the value of id is not one of the strings listed in the decoder
long <- long %>% filter(id %in% unique(decoder$id))
#2) If a temperature probe value is 0.000
long <- long[long$value != 0.000,]
#3) If a HAvg or UAvg value is 0.000
#long <- long[long$HAvg != 0.000 & long$UAvg!= 0.000,]

#Query the remaining unique ids
unique(long$id)

#Figure out which of these ids have normal temperature values by asking for the summary for each id 
for (i in 1:length(unique(long$id))) {
  print(summary(long[long$id == unique(long$id)[i],]))
}  
```

####Format date and time on all dataframes
```{r}
long$time <- as.POSIXct(long$time)

#comment/uncomment for 2015/2016 data
long <- long %>% filter(long$time < "2016-01-01" & !is.na(long$time)) #2015 data
#long <- long %>% filter(long$time > "2016-05-13" & !is.na(long$time)) #2016 data

decoder$start_date <- as.POSIXct(decoder$start_date, format = "%m/%d/%y")
decoder$end_date <- as.POSIXct(decoder$end_date, format = "%m/%d/%y")

heatstat$date <- as.POSIXct(heatstat$date, format = "%Y-%m-%d")

#comment/uncomment for 2015/2016 data
decoder <- decoder %>% filter(decoder$start_date < "2016-01-01") #2015 data
#decoder <- decoder %>% filter(decoder$start_date > "2016-01-01") #2016 data

decoder$start_time <- paste(decoder$start_date, decoder$start_time)
decoder$end_time <- paste(decoder$end_date, decoder$end_time)

decoder$start_time <- as.POSIXct(decoder$start_time)
decoder$end_time <- as.POSIXct(decoder$end_time)
```

####Assign proper block and regStat to given control box id
```{r}
long$block <- "unknown"
long$type <- "unknown"

for(i in 1:length(decoder$id)){
  box <- decoder$id[i]
  block <- decoder$block[i]
  type <- decoder$board_type[i]
  starttime <- decoder$start_time[i]
  endtime <- decoder$end_time[i]
  
  long$block <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, block, long$block)
  
  long$type <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, type, long$type)
}
```

####Clean 2016 data, based on when I know probes were faulty or mislabeled
#run this chunk only for 2016 data
```{r}
#For block 1 from 6/14/16 until 10/14/16, U and H were swapped for regulator probes, starting a ~19:00 except for the 35 and 50 cm depths.  Swap H and U for the affected data.  
long <- long %>% full_join(long %>% filter(id == "89A1" & time >= "2016-06-14 18:02:30" & time <= "2016-10-14 14:49:38" & regStat == "R") %>% full_join(long %>% filter(id == "B7D1" & time >= "2016-06-14 19:01:28" & time <= "2016-10-14 14:46:40" & regStat == "R")) %>% mutate(UH.swap = "yes"))

long <- long %>% filter(is.na(UH.swap)) %>% full_join(long %>% filter(!is.na(UH.swap)) %>% mutate(heatStat = if_else(heatStat == "U", "H", "U"))) %>% select(-UH.swap)

#Create a variable for flagging bad data
long <- long %>% mutate(flag = NA)

#Flag the following bad traces:
#Block 1, Monitor, dist = 10, depth = 20, heatStat = U
#Block 2, Monitor, dist = 8
#Block 2, Monitor, dist = 6, heatStat = H
#Block 3, Ctl, dist = 8, depth = 25, heatStat = H
#Block 3, Ctl, dist = 6, depth = 20
#Block 4, Monitor, dist = 10, depth = 50, heatStat = H
#Block 4, Ctl, dist = 8, depth = 5, heatStat = H, date > 2016-06-01
long <- long %>% mutate(flag = ifelse(date > "2016-01-01" & block == "1" & type == "Monitor" & dist == "10" & depth == "20" & heatStat == "U", "badProbe", ifelse(date > "2016-01-01" & block == "2" & type == "Monitor" & dist == "8", "badProbe", ifelse(date > "2016-01-01" & block == "2" & type == "Monitor" & dist == "6" & heatStat == "H", "badProbe", ifelse(date > "2016-01-01" & block == "3" & type == "Ctl" & dist == "8" & depth == "25" & heatStat == "H", "badProbe", ifelse(date > "2016-01-01" & block == "3" & type == "Ctl" & dist == "6" & depth == "20", "badProbe", ifelse(date > "2016-01-01" & block == "4" & type == "Monitor" & dist == "10" & depth == "50" & heatStat == "H", "badProbe", ifelse(block == "4" & type == "Ctl" & dist == "8" & depth == "5" & heatStat == "H" & date > "2016-06-01", "badTrace", flag))))))))
```

####Clean 2015 data, based on when I know probes were faulty or mislabeled
#comment out this chunk for 2016 data
```{r}
#Block 2, type = Monitor, dist = 10 from 2015-08-06 21:00:00 until 2015-09-30 23:59:59: U and H were swapped.  
long <- long %>% full_join(long %>% filter(block == 2, type == "Monitor", dist == 10, time >= "2015-08-06 21:00:00", time <= "2015-09-30 23:59:59") %>% mutate(UH.swap = "yes"))

long <- long %>% filter(is.na(UH.swap)) %>% full_join(long %>% filter(!is.na(UH.swap)) %>% mutate(heatStat = if_else(heatStat == "U", "H", "U"))) %>% select(-UH.swap)

#Create a variable for flagging bad data
long <- long %>% mutate(flag = NA) #uncomment for 2015 data

#Flag the bad traces:

#Block 2, type = Monitor, 2015-09-12 22:00:00 until 2015-09-30 23:59:59
long <- long %>% mutate(flag = ifelse(block == 2 & type == "Monitor" & time >= "2015-09-12 22:00:00" & time <= "2015-09-30 23:59:59", "badTrace", flag))

#Block 2, type = Monitor, 2015-10-14: points before 17:00:00 are bad
long <- long %>% mutate(flag = ifelse(block == 2 & type == "Monitor" & time >= "2015-10-14 00:00:00" & time < "2015-10-14 17:00:00", "badTrace", flag))

#Block 2, type = Ctl, after 2015:10:14: trace is mislabeled
long <- long %>% mutate(flag = ifelse(block == 2 & date >= "2015-10-14" & type == "Ctl", "mislabeled", flag))

#Block 3, type = Monitor, 2015-09-13 02:25:00 until 2015-09-30 23:59:59: bad trace.  (Identify the exact time) 
long <- long %>% mutate(flag = ifelse(block == 3 & type == "Monitor" & time >= "2015-09-13 02:25:00" & time <= "2015-09-30 23:59:59", "badTrace", flag))

#Block 3, type = Monitor, dist = 10, heatStat = U, 2015-10-14 00:00:00 on
long <- long %>% mutate(flag = ifelse(block == 3 & type == "Monitor" & dist == 10 & heatStat == "U" & time >= "2015-10-14", "badTrace", flag))

#Block 4, type = Monitor, before 2015-08-14 23:59:59
long <- long %>% mutate(flag = ifelse(block == 4 & type == "Monitor" & time < "2015-08-14", "badTrace", flag))
```

####Determine how frequently data are recorded
This Code should be fixed or deleted after I figure out how to deal with the 2015 data.
```{r}
# test <- long %>% filter(date >= "2015-10-14", date <= "2015-10-18", block == 2, type == "Ctl") %>% arrange(heatStat, dist, depth, time)
# 
# testplot <- ggplot(test %>% filter(as.numeric(log) < 125000), aes(y = as.numeric(log), x = time)) +
#   geom_point(size = 0.1)
# testplot
# ggsave("Ctl2_log_201510.png", path="plots", width = 14, height = 10, dpi = 300)
# 
# test2 <- long %>% filter(date >= "2015-10-14", date <= "2015-10-18", block == 2, type == "Monitor") %>% arrange(heatStat, dist, depth, time)
# 
# testplot2 <- ggplot(test2 %>% filter(as.numeric(log) < 125000), aes(y = as.numeric(log), x = time)) +
#   geom_point(size = 0.1)
# testplot2
# ggsave("Monitor2_log_201510.png", path="plots", width = 14, height = 10, dpi = 300)
# 
# t1 <- long %>% filter(block == 1, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)
# 
# t2 <- long %>% filter(block == 2, depth == 5, type == "Monitor", heatStat == "H", regStat == "M", dist == 10)
# 
# t3 <- long %>% filter(block == 3, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)
# 
# t4 <- long %>% filter(block == 4, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)
# 
# MyDatesTable.t1 <- data.frame(table(cut(t1$time, breaks="hour")))
# MyDatesTable.t1 %>% filter(Freq > 120) #If data are recorded every 30 seconds, there should be 120 occurrances per hour.  When Freq > 120, data are being recorded more frequently.
# 
# MyDatesTable.t2 <- data.frame(table(cut(t2$time, breaks="hour")))
# MyDatesTable.t2 %>% filter(Freq > 120)
# 
# MyDatesTable.t3 <- data.frame(table(cut(t3$time, breaks="hour")))
# MyDatesTable.t4 %>% filter(Freq > 120)
# 
# MyDatesTable.t4 <- data.frame(table(cut(t4$time, breaks="hour")))
# MyDatesTable.t4 %>% filter(Freq > 120)
# 
# t1.082417 <- t1 %>% filter(time > "2015-08-24 17:00:00", time < "2015-08-24 17:59:59")
# #In this example, Freq = 320.  Here, data are recorded every 30 seconds.  Additionally, data are recorded every 3 seconds from 17:21 through 17:35.
# #For this window, if I want the data every 30 seconds, I can use just the data points with "log" == multiple of 10.
# 
# t2.101601 <- t2 %>% filter(time > "2015-10-16 01:00:00", time < "2015-10-16 01:59:59")
# #In this example, Freq = 359.  Here, something weird is going on.  It looks like data are recorded every 30 seconds, but there's a completely different data stream for each HeaterSetting value.  Which HeaterSetting value is correct?  Or are they all correct, but something else is mislabeled?
# 
# t2.080620 <- t2 %>% filter(time > "2015-08-06 20:00:00", time < "2015-08-06 20:59:59")
# #In this example, Freq = 230.  Here, data are recorded every 30 seconds for the first 32 minutes, plus every 3 seconds from 20:22 through 20:31.  No data were recorded from 20:32 through 20:59.
# #For this window, I canjust use the data points with "log" == multiple of 10 to filter out the 3-second data.
# 
# 
# t1.filter <- t1 %>% filter(as.numeric(log) %% 10 == 0) #Filter out any data for which the log value is not a multiple of 10
# t2.filter <- t2 %>% filter(as.numeric(log) %% 10 == 0)
# 
# MyDatesTable.t1.filter <- data.frame(table(cut(t1.filter$time, breaks="hour")))
# MyDatesTable.t1.filter %>% filter(Freq > 120)
# #For t1, this filtering seems to have gotten rid of all the data recorded at weird intervals
# 
# MyDatesTable.t2.filter <- data.frame(table(cut(t2.filter$time, breaks="hour")))
# MyDatesTable.t2.filter %>% filter(Freq > 120)
# #The weird thing with multiple data streams recording at the same time under different HeaterSetting values happened from 10-14 17:00 through 10-17 23:00

```

####2015 data (skip this chunk for 2016 data)
####Flag outliers on all time series recorded at 30 second intervals
####calculate the sd and mean over every 1-hour window
####if value is more than 2 sigma from the mean, flag it as an outlier
```{r}
#filter all measurements that are wildly too high or too low
long <- long %>% mutate(flag = if_else(value >= 20 & is.na(flag), "outlier", if_else(value <= -5 & is.na(flag), "outlier", flag)))

flagged <- long[0:0,]
depths <- unique(long$depth)
board_type <- unique(long$type)
heatStat <- unique(long$heatStat)
regStat <- unique(long$regStat)
dist <- unique(long$dist)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) FUN(vec[(i-min(i, width/2)):(i+width/2)], na.rm=T))

combinations <- long %>% select(block, depth, type, heatStat, regStat, dist) %>% distinct()

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  #swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
  
  early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance, is.na(flag))
  
#To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
  early$timestamp <- floor_date(early$time, "0.5 mins")

#(2) Gap-fill the dataset so there is a row every 30 seconds.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 

  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 

  early <- timestamps %>% full_join(early) %>% arrange(timestamp)
  
  earlysd <- myrollapply(early$value, 120, sd)
  earlymean <- myrollapply(early$value, 120, mean)
  early[,"sd"] <- earlysd
  early[,"mean"] <- earlymean
  early$diff <- early$value - early$mean
  early$band <- early$sd*2
  early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
          
  flagged <- rbind(flagged, early)

}

#Drop objects to free up memory
#rm(long)
#gc()

#Omit gap-filled timestamps
flagged <- flagged %>% filter(!is.na(time))

#Assign outlier status to all values that are alone within the rolling window
flagged <- flagged %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit repeated rows
#flagged <- flagged %>% unique() #too memory intensive

#Merge with the rows that were previously flagged
flagged <- flagged %>% bind_rows(long %>% filter(!is.na(flag)))

```

####2016 data (skip this chunk for 2015 data)
####Flag outliers on all time series recorded at 30 second intervals
####calculate the sd and mean over every 1-hour window
####if value is more than 2 sigma from the mean, flag it as an outlier
```{r}
#filter all measurements that are wildly too high or too low
long <- long %>% mutate(flag = if_else(value >= 20 & is.na(flag), "outlier", if_else(value <= -5 & is.na(flag), "outlier", flag)))

flagged.early <- long[0:0,]
depths <- unique(long$depth)
board_type <- unique(long$type)
heatStat <- unique(long$heatStat)
regStat <- unique(long$regStat)
dist <- unique(long$dist)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) FUN(vec[(i-min(i, width/2)):(i+width/2)], na.rm=T))

combinations <- long %>% select(block, depth, type, heatStat, regStat, dist) %>% distinct()

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
  
  early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance, time < swap[1,1], is.na(flag))
  
#To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
  early$timestamp <- floor_date(early$time, "0.5 mins")

#(2) Gap-fill the dataset so there is a row every 30 seconds.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 

  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 

  early <- timestamps %>% full_join(early) %>% arrange(timestamp)
  
  earlysd <- myrollapply(early$value, 120, sd)
  earlymean <- myrollapply(early$value, 120, mean)
  early[,"sd"] <- earlysd
  early[,"mean"] <- earlymean
  early$diff <- early$value - early$mean
  early$band <- early$sd*2
  early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
          
  flagged.early <- rbind(flagged.early, early)

}

#Assign outlier status to all values that are alone within the rolling window
flagged.early <- flagged.early %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit repeated rows and gap-filled timestamps
flagged.early <- flagged.early %>% unique() %>% filter(!is.na(value))

```

####2016 data (skip this chunk for 2015 data)
####Flag outliers on all time series recorded at 5 minute intervals
####use 4-hour rolling window
```{r}

flagged.late <- long[0:0,]

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
  
  late <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time >= swap[1,1], is.na(flag))

#In order to select a 4-hour rolling window, gap-fill the dataset so that is a row for every 5-minute time interval.  This deals with the issue of missing values in the dataset by adding NA rows for these missing values, with an appropriate time stamp.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 5-minute window (because while they are recorded approximately every 5 minutes, the clock occasionally shifts by a second or two).
  late$timestamp <- floor_date(late$time, "5 mins")

#(2) To make sure there is exactly one measurement every 5 minutes, compute a 5-minute average
  mean.5min <- late %>% group_by(timestamp) %>% summarize(value.5min = mean(value, na.rm = T))

#(3) Gap-fill the dataset so there is a row every 5 minutes.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(mean.5min$timestamp)) == 0, mean.5min, data.frame(timestamp =seq(min(mean.5min$timestamp), max(mean.5min$timestamp), 300)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(mean.5min$timestamp)) == 0) {mean.5min$timestamp <- as.integer(mean.5min$timestamp)} 
  
  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
  
  mean.5min <- timestamps %>% full_join(mean.5min) %>% arrange(timestamp)
          
  latesd <- myrollapply(mean.5min$value.5min, 48, sd)
  latemean <- myrollapply(mean.5min$value.5min, 48, mean)
  mean.5min[,"sd"] <- latesd
  mean.5min[,"mean"] <- latemean
  mean.5min$diff <- mean.5min$value.5min - mean.5min$mean
  mean.5min$band <- mean.5min$sd*2
  
  mean.5min$flag <- ifelse(abs(mean.5min$diff) > mean.5min$band, "outlier", NA)
               
  if(length(is.na(late$timestamp)) == 0) {late$timestamp <- as.integer(late$timestamp)} 

  late <- mean.5min %>% mutate(flag = as.character(flag)) %>% full_join(late %>% mutate(flag = as.character(flag)))
  
  flagged.late <- flagged.late %>% bind_rows(late)

}

#Assign outlier status to all values that are alone within the rolling window
flagged.late <- flagged.late %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit repeated rows and gap-filled timestamps
flagged.late <- flagged.late %>% unique() %>% filter(!is.na(value))

flagged <- flagged.late %>% bind_rows(flagged.early)

test <- flagged %>% bind_rows(long %>% filter(!is.na(flag)))


```

Save flagged dataframe (the original dataset plus outlier flags)
```{r}
#write.csv(flagged, file = "data/2016_organized/flaggedBarrowFile_2016_5.csv") 
write.csv(flagged, file = "data/2015_organized/flaggedBarrowFile_2015.csv") 
```

####Optional: read in flagged file and format time variable
```{r}
#flagged <- read.csv('data/2016_organized/flaggedBarrowFile_2016_5.csv', stringsAsFactors=F) 

#flagged <- read.csv('data/2015_organized/flaggedBarrowFile_2015.csv', stringsAsFactors=F) 

#flagged$time <- as.POSIXct(flagged$time)
```

####To visualize outliers
```{r}
plottheme <- theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) +
  theme(axis.text.y = element_text(color="black", size=12)) +
  theme(axis.text.x = element_text(color="black", size=12, angle=90, vjust=.5)) +
  theme(axis.title.y = element_text(size=14)) +
  theme(axis.title.x = element_blank()) +
  theme(legend.position = c(.9, .85)) +
  theme(legend.title = element_text(size=14)) +
  theme(legend.text = element_text(size=12))

#outliers <- flagged %>% filter(add criteria here)
outliers <- flagged %>% filter(date == "2016-06-17", block == 1, heatStat == "U", )

outlierplot <- ggplot(outliers, aes(y = value, x = time)) +
  #geom_point(pch = 1, color = flag) +
  geom_point() +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time")
print(outlierplot + plottheme)
```

####add column for heater status (ON vs. OFF)
```{r}

```

####Average every 15 minutes. 
```{r}
  floor_datetime <- function(date_var, floor_seconds = 60, 
        origin = "1970-01-01") { # defaults to minute rounding
     if(!is(date_var, "POSIXct")) stop("Please pass in a POSIXct variable")
     if(is.na(date_var)) return(as.POSIXct(NA)) else {
        return(as.POSIXct(floor(as.numeric(date_var) / 
           (floor_seconds))*(floor_seconds), origin = origin))
     }
  }

flagged$time_15min <- floor_datetime(flagged$time, 15 * 60)

flagged <- flagged %>% mutate(flag = ifelse(flag == "NA", NA, flag))

#calculate the average for each plot and depth for each 15-minute interval
mean.15min <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_15min, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.15min.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_15min, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 

```

####Average every hour
```{r}
flagged$time_hour <- floor_datetime(flagged$time, 60 * 60)

#calculate the average for each plot and depth for each 1-hour interval
mean.hour <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_hour, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.hour.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_hour, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 

```

####Average every 4 hours
```{r}
flagged$time_4hour <- floor_datetime(flagged$time, 240 * 60)

#calculate the average for each plot and depth for each 1-hour interval
mean.4hour <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_4hour, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.4hour.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_4hour, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 
```

####Average every 6 hours
```{r}
flagged$time_6hour <- floor_datetime(flagged$time, 360 * 60)

#calculate the average for each plot and depth for each 1-hour interval
mean.6hour <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_6hour, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.6hour.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_6hour, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 

```

####Write to csv files
```{r}
#temperatures averaged for each plot and depth for every 15-min interval, outliers omitted

#write.csv(mean.15min, file = "data/2016_organized/flaggedBarrowFile.15min_2016_4.csv") 
write.csv(mean.15min, file = "data/2015_organized/flaggedBarrowFile.15min_2015.csv") 

#temperatures averaged for each probe, every 15-min interval, outliers omitted
#write.csv(mean.15min.probe, file = "data/2016_organized/flaggedBarrowFile.15min.probe_2016_4")
write.csv(mean.15min.probe, file = "data/2015_organized/flaggedBarrowFile.15min.probe_2015")

#temperatures averaged for each plot and depth for every 1-hour interval, outliers omitted
#write.csv(mean.hour, file = "data/2016_organized/flaggedBarrowFile.1hour_2016_4.csv") 
write.csv(mean.hour, file = "data/2015_organized/flaggedBarrowFile.1hour_2015.csv") 

#temperatures averaged for each probe, every 1-hour interval, outliers omitted
#write.csv(mean.hour.probe, file = "data/2016_organized/flaggedBarrowFile.1hour.probe_2016_4")
write.csv(mean.hour.probe, file = "data/2015_organized/flaggedBarrowFile.1hour.probe_2015")

#temperatures averaged for each plot and depth for every 4-hour interval, outliers omitted
#write.csv(mean.4hour, file = "data/2016_organized/flaggedBarrowFile.4hour_2016_4.csv") 
write.csv(mean.4hour, file = "data/2015_organized/flaggedBarrowFile.4hour_2015.csv") 

#temperatures averaged for each probe, every 4-hour interval, outliers omitted
#write.csv(mean.4hour.probe, file = "data/2016_organized/flaggedBarrowFile.4hour.probe_2016_4")
write.csv(mean.4hour.probe, file = "data/2015_organized/flaggedBarrowFile.4hour.probe_2015")

#temperatures averaged for each plot and depth for every 6-hour interval, outliers omitted
#write.csv(mean.6hour, file = "data/2016_organized/flaggedBarrowFile.6hour_2016_4.csv") 
write.csv(mean.6hour, file = "data/2015_organized/flaggedBarrowFile.6hour_2015.csv") 

#temperatures averaged for each probe, every 6-hour interval, outliers omitted
#write.csv(mean.6hour.probe, file = "data/2016_organized/flaggedBarrowFile.6hour.probe_2016_4")
write.csv(mean.6hour.probe, file = "data/2015_organized/flaggedBarrowFile.6hour.probe_2015")
```

####Calculate the depth-averaged temperatures in each plot for each 15-minute, 1-hour, 4-hour, and 6-hour time period.  Also calculate the difference between the heated and unheated plot for each block.  Do not use depth == 25, since it is missing from most (but not all) data streams.  Also do not use depth == 15, because it is missing from a large chunk of block 1 and 2.    Use only complete cases (i.e., where data exist for all non-15cm and non-25cm depths).
#Fix this to change the way of identifying complete cases. - I think I need to group on dist also.
```{r}
#use mean.15min for 15-min depth average, etc.
#identify complete cases (where all depths are present excepth for 15 and 25 cm)
#average across the depths, using complete cases only.

#15-min average
mean.15min <-mean.15min %>% full_join(mean.15min %>% filter(depth != 25 & depth != 15) %>% group_by(time_15min, block, heatStat) %>% summarize(depths = length(depth))) 

mean.15min.depthavg <- mean.15min %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(block, time_15min) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.15min %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(block, time_15min) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)


#15-min average
mean.hour <-mean.hour %>% full_join(mean.hour %>% filter(depth != 25, depth != 15) %>% group_by(time_hour, block, heatStat) %>% summarize(depths = length(depth))) 

mean.hour.depthavg <- mean.hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(block, time_hour) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(block, time_hour) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)


#4-hour average
mean.4hour <-mean.4hour %>% full_join(mean.4hour %>% filter(depth != 25, depth != 15) %>% group_by(time_4hour, block, heatStat) %>% summarize(depths = length(depth))) 

mean.4hour.depthavg <- mean.4hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(block, time_4hour) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.4hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(block, time_4hour) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)


#6-hour average
mean.6hour <-mean.6hour %>% full_join(mean.6hour %>% filter(depth != 25, depth != 15) %>% group_by(time_6hour, block, heatStat) %>% summarize(depths = length(depth))) 

mean.6hour.depthavg <- mean.6hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(block, time_6hour) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.6hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(block, time_6hour) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

```

####Save processed dataframes
```{r}
#temperatures averaged across all depths for every 15-minute interval, outliers ommitted
#write.csv(mean.15min.depthavg, file = "data/2016_organized/flaggedBarrowFile.15min.avg_2016_4.csv") 
write.csv(mean.15min.depthavg, file = "data/2015_organized/flaggedBarrowFile.15min.avg_2015.csv") 

#write.csv(mean.hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.1hour.avg_2016_4.csv") 
write.csv(mean.hour.depthavg, file = "data/2015_organized/flaggedBarrowFile.1hour.avg_2015.csv") 

#write.csv(mean.4hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.4hour.avg_2016_4.csv") 
write.csv(mean.4hour.depthavg, file = "data/2015_organized/flaggedBarrowFile.4hour.avg_2015.csv") 

#write.csv(mean.6hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.6hour.avg_2016_4.csv") 
write.csv(mean.6hour.depthavg, file = "data/2015_organized/flaggedBarrowFile.6hour.avg_2015.csv") 

#voltageBarrow.15min_2016.csv (voltage averaged for each 15-min interval)
```

####remove this chunk after testing code above
####this code works for outlier detection (tested this before running as the for loop above)
```{r}
#isolate block 2, 5 cm depth, control board, heated, monitor, early measurements
plot <- "3"
cm <- "20"
MC <- "Ctl"
HU <- "H"
RM <- "M"

swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)

early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time <= swap[1])

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#first pass identifying outliers
#calculate the sd and mean over every 1-hour window
#if value is more than 2 sigma from the mean, flag it as an outlier
earlysd <- myrollapply(early$value, 120, sd)
earlymean <- myrollapply(early$value, 120, mean)
early[,"sd"] <- earlysd
early[,"mean"] <- earlymean
early$diff <- early$value - early$mean
early$band <- early$sd*3
early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
length(early[early$flag == "outlier"&!is.na(early$flag),]$flag)

outlierplot <- ggplot(early %>% filter(date == "2016-06-03"), aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)
```

####remove this chunk after testing code above
####Test for outlier detection
```{r}
longtest <- long %>% filter(block == 2) %>% filter(flag != "outlier") %>% filter(regStat == "R") %>% filter(time > "2016-09-14 00:00:00" & time < "2016-09-20 23:59:59")

testplot <- ggplot(longtest %>% filter(value <= 10 & value >= -10), aes(y = value, x = time, color = heatStat)) +
  geom_point(pch = 1) +
  facet_grid(depth~.) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") +
  scale_color_discrete(name = "Heater status", breaks = c("H", "U"), labels = c("Heated", "Unheated")) 
  
print(testplot + plottheme)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#make a subset dataframe on which to do outlier detection
h5 <- longtest %>% filter(depth == "5") %>% filter(heatStat == "H")

#gap-fill the dataset so that there are observations every 5 minutes (fill with NA if no observation was recorded)
h5$min <- as.POSIXct(format(h5$time, "%Y-%m-%d %H:%M"))
z <- zoo(seq_along(h5$min), h5$min)
g <- zoo(, seq(start(z), end(z), 300))
zm <- merge(g, z)
h5 <- fortify.zoo(zm) %>% select("Index") %>% rename(min = Index) %>% full_join(h5)


#first pass identifying outliers
#calculate the sd and mean over every 4-hour time window
#if value is more than 2 sigma from the mean, flag it as an outlier
h5sd <- myrollapply(h5$value, 48, sd)
h5mean <- myrollapply(h5$value, 48, mean)
h5[,"sd"] <- h5sd
h5[,"mean"] <- h5mean
h5$diff <- h5$value - h5$mean
h5$band <- h5$sd*2
h5$flag <- NA
h5$flag <- ifelse(abs(h5$diff) > h5$band, "outlier", h5$flag)
length(h5[h5$flag == "outlier"&!is.na(h5$flag),]$flag)

outlierplot <- ggplot(h5, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)

#second pass to flag remaining outliers
h5.2 <- h5 %>% filter(is.na(flag))
h5.2sd <- myrollapply(h5.2$value, 30, sd)
h5.2mean <- myrollapply(h5.2$value, 30, mean)
h5.2[,"sd"] <- h5.2sd
h5.2[,"mean"] <- h5.2mean
h5.2$diff <- h5.2$value - h5.2$mean
h5.2$band <- h5.2$sd*2.5
h5.2$flag <- NA
h5.2$flag <- ifelse(abs(h5.2$diff) > h5.2$band, "outlier", h5.2$flag)
length(h5.2[h5.2$flag == "outlier"&!is.na(h5.2$flag),]$flag)

outlierplot2 <- ggplot(h5.2, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time")
print(outlierplot2 + plottheme)

h5 <- h5.2 %>% full_join(h5 %>% filter(flag == "outlier"))
```
