---
title: "Microwarming_data_formatting"
author: "Lydia Vaughn"
date: "22/05/2018"
output: html_document
---
#Description
```
This script reformats and processes data saved in line 249 of the "Barrow Data" script.  Processing includes outlier detection and recoding data with associated plot numbers.  The data originate from an field soil warming experiment in Barrow, Alaska.

Notes on column headers:
Uavg = the average of the regulator probes (regStat = "R") in the unheated plots (heatStat = "U") between depths of 10 and 25 cm (depth = c(10, 15, 20, 25))
```
#Code

##Install required packages

These packages only need to be installed once, then this code can be commented out or deleted.

Often, knitr does not like to install from the command window. If this is the case, look to the bottom right window and click on Packages -> Install -> and search for `knitr` in the window that opens.  

Knitr will provide a row of buttons across the top of the top left window in RStudio which allow you to view this document in html format (by clicking on the "Knit HTML" button), as well as run some or all of the code chunks below (by clicking on the "Chunks" button)

```{r}
#uncomment to install packages from command line
#install.packages("knitr")
#install.packages("zoo")
#install.packages("tidyverse")
#install.packages("lubridate")
```

####Read in files
```{r}
#missing some data:
#long <- read.csv('data/2015_organized/longBarrowFile_2015.csv', stringsAsFactors=F) 

#complete 2016 dataset:
long <- read.csv('data/2016_organized/longBarrowFile_2016_3.csv', stringsAsFactors=F) 

#comment/uncomment to change for 2015 vs. 2016 data

decoder <- read.csv('data/control_box_decoder.csv', stringsAsFactors=F)
```

####Packages
```{r}
library(tidyverse)
library(lubridate)
library(zoo)
```

####QA/QC full dataset
```{r}
unique(long$id)
#Drop the row if:

#1) If the value of id is not one of the strings listed in the decoder
long <- long %>% filter(id %in% unique(decoder$id))
#2) If a temperature probe value is 0.000
long <- long[long$value != 0.000,]
#3) If a HAvg or UAvg value is 0.000
#long <- long[long$HAvg != 0.000 & long$UAvg!= 0.000,]
```

####Format date and time on both stpreadsheets
```{r}
long$time <- as.POSIXct(long$time)

#2016 data only:
long <- long %>% filter(long$time > "2016-05-13" & !is.na(long$time))

decoder$start_date <- as.POSIXct(decoder$start_date, format = "%Y-%m-%d")
decoder$end_date <- as.POSIXct(decoder$end_date, format = "%Y-%m-%d")

#comment/uncomment for 2015/2016 data
decoder <- decoder %>% filter(decoder$start_date > "2016-01-01") #2016 data
#decoder <- decoder %>% filter(decoder$start_date < "2016-01-01") #2015 data

decoder$start_time <- paste(decoder$start_date, decoder$start_time)
decoder$end_time <- paste(decoder$end_date, decoder$end_time)

decoder$start_time <- as.POSIXct(decoder$start_time)
decoder$end_time <- as.POSIXct(decoder$end_time)
```

####Assign proper block and regStat to given control box id
```{r}
long$block <- "unknown"
long$type <- "unknown"

for(i in 1:length(decoder$id)){
  box <- decoder$id[i]
  block <- decoder$block[i]
  type <- decoder$board_type[i]
  starttime <- decoder$start_time[i]
  endtime <- decoder$end_time[i]
  
  long$block <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, block, long$block)
  
  long$type <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, type, long$type)
}

long <- na.omit(long)
```

####Calculate the number of measurements for each value of the type variable
```{r}
long %>% group_by(type) %>% summarize(length(type))
long %>% group_by(block) %>% summarize(length(block))

long %>% group_by(type, block) %>% summarize(length(type))
```

####Determine how frequently data are recorded
This Code should be fixed or deleted after I figure out how to deal with the 2015 data.
```{r}
t1 <- long %>% filter(block == 1, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)

t2 <- long %>% filter(block == 2, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)

MyDatesTable.t1 <- data.frame(table(cut(t1$time, breaks="hour")))
MyDatesTable.t1 %>% filter(Freq > 120) #If data are recorded every 30 seconds, there should be 120 occurrances per hour.  When Freq > 120, data are being recorded more frequently.

MyDatesTable.t2 <- data.frame(table(cut(t2$time, breaks="hour")))
MyDatesTable.t2 %>% filter(Freq > 120)

t1.082417 <- t1 %>% filter(time > "2015-08-24 17:00:00", time < "2015-08-24 17:59:59")
#In this example, Freq = 320.  Here, data are recorded every 30 seconds.  Additionally, data are recorded every 3 seconds from 17:21 through 17:35.
#For this window, if I want the data every 30 seconds, I can use just the data points with "log" == multiple of 10.

t2.101601 <- t2 %>% filter(time > "2015-10-16 01:00:00", time < "2015-10-16 01:59:59")
#In this example, Freq = 359.  Here, something weird is going on.  It looks like data are recorded every 30 seconds, but there's a completely different data stream for each HeaterSetting value.  Which HeaterSetting value is correct?  Or are they all correct, but something else is mislabeled?

t2.080620 <- t2 %>% filter(time > "2015-08-06 20:00:00", time < "2015-08-06 20:59:59")
#In this example, Freq = 230.  Here, data are recorded every 30 seconds for the first 32 minutes, plus every 3 seconds from 20:22 through 20:31.  No data were recorded from 20:32 through 20:59.
#For this window, I canjust use the data points with "log" == multiple of 10 to filter out the 3-second data.


t1.filter <- t1 %>% filter(as.numeric(log) %% 10 == 0) #Filter out any data for which the log value is not a multiple of 10
t2.filter <- t2 %>% filter(as.numeric(log) %% 10 == 0)

MyDatesTable.t1.filter <- data.frame(table(cut(t1.filter$time, breaks="hour")))
MyDatesTable.t1.filter %>% filter(Freq > 120)
#For t1, this filtering seems to have gotten rid of all the data recorded at weird intervals

MyDatesTable.t2.filter <- data.frame(table(cut(t2.filter$time, breaks="hour")))
MyDatesTable.t2.filter %>% filter(Freq > 120)
#The weird thing with multiple data streams recording at the same time under different HeaterSetting values happened from 10-14 17:00 through 10-17 23:00

```

####Flag outliers on all time series recorded at 30 second intervals
####calculate the sd and mean over every 1-hour window
####if value is more than 2 sigma from the mean, flag it as an outlier
```{r}
#filter all measurements that are wildly too high or too low
long$flag <- ifelse(long$value >= 20 | long$value <= -20, "outlier", "NA")

flagged <- long[0:0,]
depths <- unique(long$depth)
board_type <- unique(decoder$board_type)
heatStat <- unique(long$heatStat)
regStat <- unique(long$regStat)
dist <- unique(long$dist)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) FUN(vec[(i-min(i, width/2)):(i+width/2)], na.rm=T))

#myrollapply <- function(vec, width, FUN) 
#    sapply(seq_along(vec), 
#           function(i) ifelse (i < width/2 | length(vec) - i < width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

for(i in 1:4){
  plot <- i
  for(j in 1:length(depths)){
    cm <- depths[j]
    for(k in 1:length(board_type)){
      MC <- board_type[k]
      for(ii in 1:length(heatStat)){
        HU <- heatStat[ii]
        for(jj in 1:length(regStat)){
          RM <- regStat[jj]
          for(kk in 1:length(dist)){
            distance <- dist[jj]
          }
          
          swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
          
          early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance, time <= swap[1,1], flag != "outlier")
   
          #To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 
       
          #(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
          early$timestamp <- floor_date(early$time, "0.5 mins")
          
          #(2) Gap-fill the dataset so there is a row every 30 seconds.  
          timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
          colnames(timestamps) = c("timestamp")
          if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 
          if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
          #timestamps <- data.frame(timestamp =  seq(min(early$timestamp), max(early$timestamp), 30))
          early <- timestamps %>% full_join(early)
          
          earlysd <- myrollapply(early$value, 120, sd)
          earlymean <- myrollapply(early$value, 120, mean)
          early[,"sd"] <- earlysd
          early[,"mean"] <- earlymean
          early$diff <- early$value - early$mean
          early$band <- early$sd*2
          early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
          
          flagged <- rbind(flagged, early)

        }
      }
    }
  }
}

#get rid of empty rows
flagged <- na.omit(flagged)
```

####Flag outliers on all time series recorded at 5 minute intervals
####use 4-hour rolling window
```{r}
# myrollapply.2 <- function(df, sec, FUN) 
#     sapply(seq_along(df$value), 
#            function(i) ifelse (df$time[i] < df$time[1] + sec | df$time[length(df$time)] - sec < df$time[i], NA, (df %>% filter(time > time[i] - sec, time < time[i] + sec) %>% summarize(FUN(value), na.rm=T))))

#testframe <- long %>% filter(block == "1", depth == "5", heatStat == "H", date %in% c("2016-06-24", "2016-06-25"))

#myrollapply(testframe, 7200, mean)

for(i in 1:4){
  plot <- i
  for(j in 1:length(depths)){
    cm <- depths[j]
    for(k in 1:length(board_type)){
      MC <- board_type[k]
      for(ii in 1:length(heatStat)){
        HU <- heatStat[ii]
        for(jj in 1:length(regStat)){
          RM <- regStat[jj]
          for(kk in 1:length(dist)){
            distance <- dist[jj]
            
          swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
          
          late <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time > swap[1,1])
  
#In order to select a 4-hour rolling window, gap-fill the dataset so that is a row for every 5-minute time interval.  This deals with the issue of missing values in the dataset by adding NA rows for these missing values, with an appropriate time stamp.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 
          #(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
          late$timestamp <- floor_date(late$time, "5 mins")
          
          #(2) To make sure there is exactly one measuremnet every 5 minutes, compute a 5-minute average
          mean.5min <- late %>% group_by(timestamp) %>% summarize(value = mean(value, na.rm = T))
          
          #(2) Gap-fill the dataset so there is a row every 30 seconds.  
          timestamps <- data.frame(timestamp = ifelse(length(!is.na(mean.5min$timestamp)) == 0, mean.5min, data.frame(timestamp =seq(min(mean.5min$timestamp), max(mean.5min$timestamp), 300)))) 
          colnames(timestamps) = c("timestamp")
          if(length(is.na(mean.5min$timestamp)) == 0) {mean.5min$timestamp <- as.integer(mean.5min$timestamp)} 
          if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
          mean.5min <- timestamps %>% full_join(mean.5min)
          
          #late$min <- as.POSIXct(format(late$time, "%Y-%m-%d %H:%M"))
          #minutes <- data.frame(min = ifelse(length(!is.na(late$min)) == 0, late, data.frame(min =seq(min(late$min), max(late$min), 60)))) 
          #colnames(minutes) = c("min")
          #if(length(is.na(late$min)) == 0) {late$min <- as.integer(late$min)} 
          #late <- minutes %>% full_join(late)

          #if the above uncommented code works, change the code below so that the window is 48 instead of 240 (the number of measurements in a 4-hour rolling window)
          latesd <- myrollapply(mean.5min$value, 48, sd)
          latemean <- myrollapply(mean.5min$value, 48, mean)
          late[,"sd"] <- latesd
          late[,"mean"] <- latemean
          late$diff <- late$value - late$mean
          late$band <- late$sd*2
          late$flag <- ifelse(abs(late$diff) > late$band, "outlier", late$flag)
          late <- late %>% filter(!is.na(value)) %>% select(-min)
          
          flagged <- rbind(flagged, late)
          }
        }
      }
    }
  }
}

flagged <- unique(flagged)
flagged <- na.omit(flagged)
```

####To visualize outliers
```{r}
# plottheme <- theme_bw() + 
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) +
#   theme(axis.text.y = element_text(color="black", size=12)) +
#   theme(axis.text.x = element_text(color="black", size=12, angle=90, vjust=.5)) +
#   theme(axis.title.y = element_text(size=14)) +
#   theme(axis.title.x = element_blank()) +
#   theme(legend.position = c(.9, .85)) +
#   theme(legend.title = element_text(size=14)) +
#   theme(legend.text = element_text(size=12)) 

#h5 <- flagged %>% filter(add critera here)

# outlierplot <- ggplot(h5, aes(y = value, x = time, color = flag)) +
#   geom_point(pch = 1) +
#   ylab(expression("Temperature" ~ (degree * C))) +
#   xlab("Time") 
# print(outlierplot + plottheme)
```

####Recalculate UAvg and HAvg, omitting outlier values.  Use only complete cases (i.e., where data exist for all depths in c(10, 15, 20, 25))
```{r}
UAvgHAvg.flagged <- flagged %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "U") %>% mutate(value2 = ifelse(flag != "outlier", value, NA)) %>% group_by(block, time, type) %>% summarize(UAvg = mean(value2)) %>% left_join(flagged %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "H", regStat == "R") %>% mutate(value2 = ifelse(flag != "outlier", value, NA)) %>% group_by(block, time, type) %>% summarize(HAvg = mean(value2))) %>% mutate(TempDiff = HAvg - UAvg)
```

####Average every 15 minutes. 
```{r}
  floor_datetime <- function(date_var, floor_seconds = 60, 
        origin = "1970-01-01") { # defaults to minute rounding
     if(!is(date_var, "POSIXct")) stop("Please pass in a POSIXct variable")
     if(is.na(date_var)) return(as.POSIXct(NA)) else {
        return(as.POSIXct(floor(as.numeric(date_var) / 
           (floor_seconds))*(floor_seconds), origin = origin))
     }
  }

#flagged$time <- as.POSIXct(flagged$time)

flagged$time_15min <- floor_datetime(flagged$time, 15 * 60)
UAvgHAvg.flagged$time_15min <- floor_datetime(UAvgHAvg.flagged$time, 15 * 60)

#calculate the average for each depth and each 15-minute interval
flagged.15min <- flagged %>% filter(flag != "outlier") %>% group_by(block, type, time_15min, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average across all depths (10-25 cm) for evey 15-minute interval.  Include only measurements that haven't been flagged as outliers.
flagged.15min.avg <- UAvgHAvg.flagged %>% group_by(block, type, time_15min) %>% summarize(UAvg_15min = mean(UAvg, na.rm=T), HAvg_15min = mean(HAvg, na.rm=T)) %>% mutate(TempDiff_15min = HAvg_15min - UAvg_15min)

#voltage.15min <- long %>% group_by(block, type, time_15min) %>% summarize(voltage = mean(Voltage))

```

####Save processed dataframes
```{r}
#the original dataset plus outlier flags
write.csv(flagged, file = "data/2016_organized/flaggedBarrowFile_2016_2.csv") 

#temperatures averaged for each depth for every 15-min interval, outliers omitted
write.csv(flagged.15min, file = "data/2016_organized/flaggedBarrowFile.15min_2016_2.csv") 

#temperatures averaged across all depths for every 15-minute interval, outliers ommitted
write.csv(flagged.15min.avg, file = "data/2016_organized/flaggedBarrowFile.15min.avg_2016_2.csv") 

#voltageBarrow.15min_2016.csv (voltage averaged for each 15-min interval)
```

####remove this chunk after testing code above
####this code works for outlier detection (tested this before running as the for loop above)
```{r}
#isolate block 2, 5 cm depth, control board, heated, monitor, early measurements
plot <- "3"
cm <- "20"
MC <- "Ctl"
HU <- "H"
RM <- "M"

swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)

early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time <= swap[1])

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#first pass identifying outliers
#calculate the sd and mean over every 1-hour window
#if value is more than 2 sigma from the mean, flag it as an outlier
earlysd <- myrollapply(early$value, 120, sd)
earlymean <- myrollapply(early$value, 120, mean)
early[,"sd"] <- earlysd
early[,"mean"] <- earlymean
early$diff <- early$value - early$mean
early$band <- early$sd*3
early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
length(early[early$flag == "outlier"&!is.na(early$flag),]$flag)

outlierplot <- ggplot(early %>% filter(date == "2016-06-03"), aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)
```

####remove this chunk after testing code above
####Test for outlier detection
```{r}
longtest <- long %>% filter(block == 2) %>% filter(flag != "outlier") %>% filter(regStat == "R") %>% filter(time > "2016-09-14 00:00:00" & time < "2016-09-20 23:59:59")

testplot <- ggplot(longtest %>% filter(value <= 10 & value >= -10), aes(y = value, x = time, color = heatStat)) +
  geom_point(pch = 1) +
  facet_grid(depth~.) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") +
  scale_color_discrete(name = "Heater status", breaks = c("H", "U"), labels = c("Heated", "Unheated")) 
  
print(testplot + plottheme)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#make a subset dataframe on which to do outlier detection
h5 <- longtest %>% filter(depth == "5") %>% filter(heatStat == "H")

#gap-fill the dataset so that there are observations every 5 minutes (fill with NA if no observation was recorded)
h5$min <- as.POSIXct(format(h5$time, "%Y-%m-%d %H:%M"))
z <- zoo(seq_along(h5$min), h5$min)
g <- zoo(, seq(start(z), end(z), 300))
zm <- merge(g, z)
h5 <- fortify.zoo(zm) %>% select("Index") %>% rename(min = Index) %>% full_join(h5)


#first pass identifying outliers
#calculate the sd and mean over every 4-hour time window
#if value is more than 2 sigma from the mean, flag it as an outlier
h5sd <- myrollapply(h5$value, 48, sd)
h5mean <- myrollapply(h5$value, 48, mean)
h5[,"sd"] <- h5sd
h5[,"mean"] <- h5mean
h5$diff <- h5$value - h5$mean
h5$band <- h5$sd*2
h5$flag <- NA
h5$flag <- ifelse(abs(h5$diff) > h5$band, "outlier", h5$flag)
length(h5[h5$flag == "outlier"&!is.na(h5$flag),]$flag)

outlierplot <- ggplot(h5, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)

#second pass to flag remaining outliers
h5.2 <- h5 %>% filter(is.na(flag))
h5.2sd <- myrollapply(h5.2$value, 30, sd)
h5.2mean <- myrollapply(h5.2$value, 30, mean)
h5.2[,"sd"] <- h5.2sd
h5.2[,"mean"] <- h5.2mean
h5.2$diff <- h5.2$value - h5.2$mean
h5.2$band <- h5.2$sd*2.5
h5.2$flag <- NA
h5.2$flag <- ifelse(abs(h5.2$diff) > h5.2$band, "outlier", h5.2$flag)
length(h5.2[h5.2$flag == "outlier"&!is.na(h5.2$flag),]$flag)

outlierplot2 <- ggplot(h5.2, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time")
print(outlierplot2 + plottheme)

h5 <- h5.2 %>% full_join(h5 %>% filter(flag == "outlier"))
```

####add column for heater status (ON vs. OFF)
```{r}

```
