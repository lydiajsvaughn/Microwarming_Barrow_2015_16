---
title: "Microwarming_data_formatting"
author: "Lydia Vaughn"
date: "22/05/2018"
output: html_document
---
#Description
```
This script reformats and processes data saved in line 249 of the "Barrow Data" script.  Processing includes outlier detection and recoding data with associated plot numbers.  The data originate from an field soil warming experiment in Barrow, Alaska.

Notes on column headers:
Uavg = the average of the regulator probes (regStat = "R") in the unheated plots (heatStat = "U") between depths of 10 and 25 cm (depth = c(10, 15, 20, 25))
```
#Code

##Install required packages

These packages only need to be installed once, then this code can be commented out or deleted.

Often, knitr does not like to install from the command window. If this is the case, look to the bottom right window and click on Packages -> Install -> and search for `knitr` in the window that opens.  

Knitr will provide a row of buttons across the top of the top left window in RStudio which allow you to view this document in html format (by clicking on the "Knit HTML" button), as well as run some or all of the code chunks below (by clicking on the "Chunks" button)

```{r}
#uncomment to install packages from command line
#install.packages("knitr")
#install.packages("zoo")
#install.packages("tidyverse")
#install.packages("lubridate")
```

####Read in files
```{r}
#missing some data:
#long <- read.csv('data/2015_organized/longBarrowFile_2015.csv', stringsAsFactors=F) 

#complete 2016 dataset:
long <- read.csv('data/2016_organized/longBarrowFile_2016_4.csv', stringsAsFactors=F) 

#comment/uncomment to change for 2015 vs. 2016 data

decoder <- read.csv('data/control_box_decoder.csv', stringsAsFactors=F)

heatstat <- read.csv('data/HeaterStatus.csv', stringsAsFactors=F)
```

####Packages
```{r}
library(tidyverse)
library(lubridate)
library(zoo)
```

####QA/QC full dataset
```{r}
unique(long$id)
#Drop the row if:

#1) If the value of id is not one of the strings listed in the decoder
long <- long %>% filter(id %in% unique(decoder$id))
#2) If a temperature probe value is 0.000
long <- long[long$value != 0.000,]
#3) If a HAvg or UAvg value is 0.000
#long <- long[long$HAvg != 0.000 & long$UAvg!= 0.000,]
#4) If a temperature probe values is greater than 20 or less than -5 (outside the range of reasonable values)
long <- long %>% filter(value <= 20 & value >= -5)

#Query the remaining unique ids
unique(long$id)

#Figure out which of these ids have normal temperature values by asking for the summary for each id 
for (i in 1:length(unique(long$id))) {
  print(summary(long[long$id == unique(long$id)[i],]))
}  
```

####Format date and time on all dataframes
```{r}
long$time <- as.POSIXct(long$time)

#2016 data only:
long <- long %>% filter(long$time > "2016-05-13" & !is.na(long$time))

decoder$start_date <- as.POSIXct(decoder$start_date, format = "%m/%d/%y")
decoder$end_date <- as.POSIXct(decoder$end_date, format = "%m/%d/%y")

heatstat$date <- as.POSIXct(heatstat$date, format = "%Y-%m-%d")

#comment/uncomment for 2015/2016 data
decoder <- decoder %>% filter(decoder$start_date > "2016-01-01") #2016 data
#decoder <- decoder %>% filter(decoder$start_date < "2016-01-01") #2015 data

decoder$start_time <- paste(decoder$start_date, decoder$start_time)
decoder$end_time <- paste(decoder$end_date, decoder$end_time)

decoder$start_time <- as.POSIXct(decoder$start_time)
decoder$end_time <- as.POSIXct(decoder$end_time)
```

####Assign proper block and regStat to given control box id
```{r}
long$block <- "unknown"
long$type <- "unknown"

for(i in 1:length(decoder$id)){
  box <- decoder$id[i]
  block <- decoder$block[i]
  type <- decoder$board_type[i]
  starttime <- decoder$start_time[i]
  endtime <- decoder$end_time[i]
  
  long$block <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, block, long$block)
  
  long$type <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, type, long$type)
}
```

####For block 1 from 6/14/16 until 10/14/16, U and H were swapped for regulator probes, starting a ~19:00 except for the 35 and 50 cm depths.  Swap H and U for the affected data.  
```{r}
#add variable indicating which data need U/H swapped.  This can take on values of "yes" or NA
long <- long %>% full_join(long %>% filter(id == "89A1" & time >= "2016-06-14 18:02:30" & time <= "2016-10-14 14:49:38" & regStat == "R") %>% full_join(long %>% filter(id == "B7D1" & time >= "2016-06-14 19:01:28" & time <= "2016-10-14 14:46:40" & regStat == "R")) %>% mutate(UH.swap = "yes"))

#swap U and H for the labeled entries
long <- long %>% filter(is.na(UH.swap)) %>% full_join(long %>% filter(!is.na(UH.swap)) %>% mutate(heatStat = if_else(heatStat == "U", "H", "U"))) %>% select(-UH.swap)
```

####Calculate the number of measurements for each value of the type variable
```{r}
long %>% group_by(type) %>% summarize(length(type))
long %>% group_by(block) %>% summarize(length(block))
long %>% group_by(type, block) %>% summarize(length(type))
```

####Determine how frequently data are recorded
This Code should be fixed or deleted after I figure out how to deal with the 2015 data.
```{r}
t1 <- long %>% filter(block == 1, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)

t2 <- long %>% filter(block == 2, depth == 5, type == "Ctl", heatStat == "U", regStat == "R", dist == 8)

t3 <- long %>% filter(date == "2016-05-15", block == 1, depth == 20, type == "Monitor", heatStat == "U", regStat == "M", dist == 10)

MyDatesTable.t1 <- data.frame(table(cut(t1$time, breaks="hour")))
MyDatesTable.t1 %>% filter(Freq > 120) #If data are recorded every 30 seconds, there should be 120 occurrances per hour.  When Freq > 120, data are being recorded more frequently.

MyDatesTable.t2 <- data.frame(table(cut(t2$time, breaks="hour")))
MyDatesTable.t2 %>% filter(Freq > 120)

MyDatesTable.t3 <- data.frame(table(cut(t3$time, breaks="hour")))
MyDatesTable.t2 %>% filter(Freq > 120)

t1.082417 <- t1 %>% filter(time > "2015-08-24 17:00:00", time < "2015-08-24 17:59:59")
#In this example, Freq = 320.  Here, data are recorded every 30 seconds.  Additionally, data are recorded every 3 seconds from 17:21 through 17:35.
#For this window, if I want the data every 30 seconds, I can use just the data points with "log" == multiple of 10.

t2.101601 <- t2 %>% filter(time > "2015-10-16 01:00:00", time < "2015-10-16 01:59:59")
#In this example, Freq = 359.  Here, something weird is going on.  It looks like data are recorded every 30 seconds, but there's a completely different data stream for each HeaterSetting value.  Which HeaterSetting value is correct?  Or are they all correct, but something else is mislabeled?

t2.080620 <- t2 %>% filter(time > "2015-08-06 20:00:00", time < "2015-08-06 20:59:59")
#In this example, Freq = 230.  Here, data are recorded every 30 seconds for the first 32 minutes, plus every 3 seconds from 20:22 through 20:31.  No data were recorded from 20:32 through 20:59.
#For this window, I canjust use the data points with "log" == multiple of 10 to filter out the 3-second data.


t1.filter <- t1 %>% filter(as.numeric(log) %% 10 == 0) #Filter out any data for which the log value is not a multiple of 10
t2.filter <- t2 %>% filter(as.numeric(log) %% 10 == 0)

MyDatesTable.t1.filter <- data.frame(table(cut(t1.filter$time, breaks="hour")))
MyDatesTable.t1.filter %>% filter(Freq > 120)
#For t1, this filtering seems to have gotten rid of all the data recorded at weird intervals

MyDatesTable.t2.filter <- data.frame(table(cut(t2.filter$time, breaks="hour")))
MyDatesTable.t2.filter %>% filter(Freq > 120)
#The weird thing with multiple data streams recording at the same time under different HeaterSetting values happened from 10-14 17:00 through 10-17 23:00

```

####Flag outliers on all time series recorded at 30 second intervals
####calculate the sd and mean over every 1-hour window
####if value is more than 2 sigma from the mean, flag it as an outlier
```{r}
#filter all measurements that are wildly too high or too low
#long$flag <- ifelse(long$value >= 20 | long$value <= -20, "outlier", "NA")

#create a variable called flag
long$flag <- NA

flagged.early <- long[0:0,]
depths <- unique(long$depth)
board_type <- unique(long$type)
heatStat <- unique(long$heatStat)
regStat <- unique(long$regStat)
dist <- unique(long$dist)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) FUN(vec[(i-min(i, width/2)):(i+width/2)], na.rm=T))

#myrollapply <- function(vec, width, FUN) 
#    sapply(seq_along(vec), 
#           function(i) ifelse (i < width/2 | length(vec) - i < width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

combinations <- long %>% select(block, depth, type, heatStat, regStat, dist) %>% distinct()

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
  
  early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance, time < swap[1,1])
  
#To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
  early$timestamp <- floor_date(early$time, "0.5 mins")

#(2) Gap-fill the dataset so there is a row every 30 seconds.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 

  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 

  early <- timestamps %>% full_join(early) %>% arrange(timestamp)
  
  earlysd <- myrollapply(early$value, 120, sd)
  earlymean <- myrollapply(early$value, 120, mean)
  early[,"sd"] <- earlysd
  early[,"mean"] <- earlymean
  early$diff <- early$value - early$mean
  early$band <- early$sd*2
  early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
          
  flagged.early <- rbind(flagged.early, early)

}

#Assign outlier status to all values that are alone within the rolling window
flagged.early <- flagged.early %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit repeated rows and gap-filled timestamps
flagged.early <- flagged.early %>% unique() %>% filter(!is.na(value))

# for(i in 1:4){
#   plot <- i
#   for(j in 1:length(depths)){
#     cm <- depths[j]
#     for(k in 1:length(board_type)){
#       MC <- board_type[k]
#       for(ii in 1:length(heatStat)){
#         HU <- heatStat[ii]
#         for(jj in 1:length(regStat)){
#           RM <- regStat[jj]
#           for(kk in 1:length(dist)){
#             distance <- dist[kk]
#             
#           
#           swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
#           
#           early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance, time < swap[1,1])
#    
#           #To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 
#        
#           #(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
#           early$timestamp <- floor_date(early$time, "0.5 mins")
#           
#           #(2) Gap-fill the dataset so there is a row every 30 seconds.  
#           timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
#           colnames(timestamps) = c("timestamp")
#           if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 
#           if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
#           #timestamps <- data.frame(timestamp =  seq(min(early$timestamp), max(early$timestamp), 30))
#           early <- timestamps %>% full_join(early) %>% arrange(timestamp)
# #          early <- timestamps %>% full_join(early) 
#           
#           earlysd <- myrollapply(early$value, 120, sd)
#           earlymean <- myrollapply(early$value, 120, mean)
#           early[,"sd"] <- earlysd
#           early[,"mean"] <- earlymean
#           early$diff <- early$value - early$mean
#           early$band <- early$sd*2
#           early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
#           
#           flagged.early <- rbind(flagged.early, early)
#           }
#         }
#       }
#     }
#   }
# }

```

####Flag outliers on all time series recorded at 5 minute intervals
####use 4-hour rolling window
```{r}
# myrollapply.2 <- function(df, sec, FUN) 
#     sapply(seq_along(df$value), 
#            function(i) ifelse (df$time[i] < df$time[1] + sec | df$time[length(df$time)] - sec < df$time[i], NA, (df %>% filter(time > time[i] - sec, time < time[i] + sec) %>% summarize(FUN(value), na.rm=T))))

#testframe <- long %>% filter(block == "1", depth == "5", heatStat == "H", date %in% c("2016-06-24", "2016-06-25"))

#myrollapply(testframe, 7200, mean)
flagged.late <- long[0:0,]

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
  
  late <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time >= swap[1,1])

#In order to select a 4-hour rolling window, gap-fill the dataset so that is a row for every 5-minute time interval.  This deals with the issue of missing values in the dataset by adding NA rows for these missing values, with an appropriate time stamp.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 5-minute window (because while they are recorded approximately every 5 minutes, the clock occasionally shifts by a second or two).
  late$timestamp <- floor_date(late$time, "5 mins")

#(2) To make sure there is exactly one measurement every 5 minutes, compute a 5-minute average
  mean.5min <- late %>% group_by(timestamp) %>% summarize(value.5min = mean(value, na.rm = T))

#(3) Gap-fill the dataset so there is a row every 5 minutes.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(mean.5min$timestamp)) == 0, mean.5min, data.frame(timestamp =seq(min(mean.5min$timestamp), max(mean.5min$timestamp), 300)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(mean.5min$timestamp)) == 0) {mean.5min$timestamp <- as.integer(mean.5min$timestamp)} 
  
  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
  
  mean.5min <- timestamps %>% full_join(mean.5min) %>% arrange(timestamp)
          
  latesd <- myrollapply(mean.5min$value.5min, 48, sd)
  latemean <- myrollapply(mean.5min$value.5min, 48, mean)
  mean.5min[,"sd"] <- latesd
  mean.5min[,"mean"] <- latemean
  mean.5min$diff <- mean.5min$value.5min - mean.5min$mean
  mean.5min$band <- mean.5min$sd*2
  
  mean.5min$flag <- ifelse(abs(mean.5min$diff) > mean.5min$band, "outlier", NA)
               
  if(length(is.na(late$timestamp)) == 0) {late$timestamp <- as.integer(late$timestamp)} 

  late <- mean.5min %>% mutate(flag = as.character(flag)) %>% full_join(late %>% mutate(flag = as.character(flag)))
  
  flagged.late <- flagged.late %>% bind_rows(late)

}

#Assign outlier status to all values that are alone within the rolling window
flagged.late <- flagged.late %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit repeated rows and gap-filled timestamps
flagged.late <- flagged.late %>% unique() %>% filter(!is.na(value))

flagged <- flagged.late %>% bind_rows(flagged.early)



# for(i in 1:4){
#   plot <- i
#   for(j in 1:length(depths)){
#     cm <- depths[j]
#     for(k in 1:length(board_type)){
#       MC <- board_type[k]
#       for(ii in 1:length(heatStat)){
#         HU <- heatStat[ii]
#         for(jj in 1:length(regStat)){
#           RM <- regStat[jj]
#           for(kk in 1:length(dist)){
#             distance <- dist[kk]
            
#           swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)
#           
#           late <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time >= swap[1,1])
#   
# #In order to select a 4-hour rolling window, gap-fill the dataset so that is a row for every 5-minute time interval.  This deals with the issue of missing values in the dataset by adding NA rows for these missing values, with an appropriate time stamp.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 
#           #(1) Assign each measurement to the beginning of a 5-minute window (because while they are recorded approximately every 5 minutes, the clock occasionally shifts by a second or two).
#           late$timestamp <- floor_date(late$time, "5 mins")
#           
#           #(2) To make sure there is exactly one measuremnet every 5 minutes, compute a 5-minute average
#           mean.5min <- late %>% group_by(timestamp) %>% summarize(value.5min = mean(value, na.rm = T))
#           
#           #(2) Gap-fill the dataset so there is a row every 30 seconds.  
#           timestamps <- data.frame(timestamp = ifelse(length(!is.na(mean.5min$timestamp)) == 0, mean.5min, data.frame(timestamp =seq(min(mean.5min$timestamp), max(mean.5min$timestamp), 300)))) 
#           colnames(timestamps) = c("timestamp")
#           if(length(is.na(mean.5min$timestamp)) == 0) {mean.5min$timestamp <- as.integer(mean.5min$timestamp)} 
#           if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
#           mean.5min <- timestamps %>% full_join(mean.5min) %>% arrange(timestamp)
#           
#           #late$min <- as.POSIXct(format(late$time, "%Y-%m-%d %H:%M"))
#           #minutes <- data.frame(min = ifelse(length(!is.na(late$min)) == 0, late, data.frame(min =seq(min(late$min), max(late$min), 60)))) 
#           #colnames(minutes) = c("min")
#           #if(length(is.na(late$min)) == 0) {late$min <- as.integer(late$min)} 
#           #late <- minutes %>% full_join(late)
# 
#           #if the above uncommented code works, change the code below so that the window is 48 instead of 240 (the number of measurements in a 4-hour rolling window)
#           latesd <- myrollapply(mean.5min$value.5min, 48, sd)
#           latemean <- myrollapply(mean.5min$value.5min, 48, mean)
#           mean.5min[,"sd"] <- latesd
#           mean.5min[,"mean"] <- latemean
#           mean.5min$diff <- mean.5min$value.5min - mean.5min$mean
#           mean.5min$band <- mean.5min$sd*2
#           
#           #mean.5min$flag <- NA
#           #mean.5min$flag <- ifelse(abs(mean.5min$diff) > mean.5min$band, "outlier", mean.5min$flag)
#           mean.5min$flag <- ifelse(abs(mean.5min$diff) > mean.5min$band, "outlier", NA)
# 
#           if(length(is.na(late$timestamp)) == 0) {late$timestamp <- as.integer(late$timestamp)} 
#           late <- mean.5min %>% mutate(flag = as.character(flag)) %>% full_join(late %>% mutate(flag = as.character(flag)))
#           
#           #late <- late %>% filter(!is.na(value.5min)) %>% select(-min)
#           
#           flagged.late <- flagged.late %>% bind_rows(late)
#           }
#         }
#       }
#     }
#   }
# }

# flagged <- flagged.late %>% bind_rows(flagged.early)
# flagged <- unique(flagged)
# flagged <- flagged %>% filter(!is.na(value))
```

Save flagged dataframe (the original dataset plus outlier flags)
```{r}
write.csv(flagged, file = "data/2016_organized/flaggedBarrowFile_2016_4.csv") 
```

####Optional: read in flagged file and format time variable
```{r}
flagged <- read.csv('data/2016_organized/flaggedBarrowFile_2016_4.csv', stringsAsFactors=F) 
flagged$time <- as.POSIXct(flagged$time)
```

####To visualize outliers
```{r}
plottheme <- theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) +
  theme(axis.text.y = element_text(color="black", size=12)) +
  theme(axis.text.x = element_text(color="black", size=12, angle=90, vjust=.5)) +
  theme(axis.title.y = element_text(size=14)) +
  theme(axis.title.x = element_blank()) +
  theme(legend.position = c(.9, .85)) +
  theme(legend.title = element_text(size=14)) +
  theme(legend.text = element_text(size=12))

#outliers <- flagged %>% filter(add criteria here)
outliers <- flagged %>% filter(date == "2016-06-17", block == 1, heatStat == "U", )

outlierplot <- ggplot(outliers, aes(y = value, x = time)) +
  #geom_point(pch = 1, color = flag) +
  geom_point() +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time")
print(outlierplot + plottheme)
```

####add column for heater status (ON vs. OFF)
```{r}

```

####Average every 15 minutes. 
```{r}
  floor_datetime <- function(date_var, floor_seconds = 60, 
        origin = "1970-01-01") { # defaults to minute rounding
     if(!is(date_var, "POSIXct")) stop("Please pass in a POSIXct variable")
     if(is.na(date_var)) return(as.POSIXct(NA)) else {
        return(as.POSIXct(floor(as.numeric(date_var) / 
           (floor_seconds))*(floor_seconds), origin = origin))
     }
  }

flagged$time_15min <- floor_datetime(flagged$time, 15 * 60)

#calculate the average for each plot and depth for each 15-minute interval
mean.15min <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_15min, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.15min.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_15min, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 

```

####Average every hour
```{r}
flagged$time_hour <- floor_datetime(flagged$time, 60 * 60)

#calculate the average for each plot and depth for each 1-hour interval
mean.hour <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_hour, heatStat, depth) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.hour.probe <- flagged %>% filter(is.na(flag)) %>% group_by(block, time_hour, heatStat, depth, regStat, dist, type) %>% summarize(temp = mean(value)) 

```

####Write to csv files
```{r}
#temperatures averaged for each plot and depth for every 15-min interval, outliers omitted
write.csv(mean.15min, file = "data/2016_organized/flaggedBarrowFile.15min_2016_4.csv") 

#temperatures averaged for each probe, every 15-min interval, outliers omitted
write.csv(mean.15min.probe, file = "data/2016_organized/flaggedBarrowFile.15min.probe_2016_4")

#temperatures averaged for each plot and depth for every 1-hour interval, outliers omitted
write.csv(mean.hour, file = "data/2016_organized/flaggedBarrowFile.1hour_2016_4.csv") 

#temperatures averaged for each probe, every 1-hour interval, outliers omitted
write.csv(mean.hour.probe, file = "data/2016_organized/flaggedBarrowFile.1hour.probe_2016_4")
```

####Calculate the depth-averaged temperatures in the heated and unheated blocks for each 15-minute time period.  Do not use depth == 25, since it is missing from most (but not all) data streams.    Use only complete cases (i.e., where data exist for all non-25cm depths).
#Fix this to change the way of identifying complete cases. - I think I need to group on dist also.
```{r}

#also do may 28 and aug 15
# testframe <- flagged %>% filter(date >= "2016-05-28" & date < "2016-05-29")
# 
# testframe %>% group_by(block, time, type, heatStat, dist, regStat) %>% summarize(depths = length(unique(depth)))
# 
# b4.5 <- testframe %>% filter(block == "4", heatStat == "U", depth == "5")
# b4.10 <- testframe %>% filter(block == "4", heatStat == "U", depth == "10")
# b4.15 <- testframe %>% filter(block == "4", heatStat == "U", depth == "15")
# b4.20 <- testframe %>% filter(block == "4", heatStat == "U", depth == "10")
# b2.25 <- testframe %>% filter(block == "2", heatStat == "U", depth == "25")
# b4.35 <- testframe %>% filter(block == "4", heatStat == "U", depth == "35")
# b4.50 <- testframe %>% filter(block == "4", heatStat == "U", depth == "50")
# 
# test.UAvgHAvg.flagged <- testframe %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "U") %>% mutate(value2 = ifelse(is.na(flag), value, NA)) %>% group_by(block, time, type, dist) %>% summarize(UAvg = mean(value2)) %>% left_join(testframe %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "H", regStat == "R") %>% mutate(value2 = ifelse(is.na(flag), value, NA)) %>% group_by(block, time, type, dist) %>% summarize(HAvg = mean(value2))) %>% mutate(TempDiff = HAvg - UAvg)


#Changed to line of code below
# UAvgHAvg.flagged <- flagged %>% filter(depth != 25, heatStat == "U") %>% mutate(value2 = ifelse(flag != "outlier", value, NA)) %>% group_by(block, time, type, dist) %>% summarize(UAvg = mean(value2)) %>% left_join(flagged %>% filter(depth != 25, heatStat == "H", regStat == "R") %>% mutate(value2 = ifelse(flag != "outlier", value, NA)) %>% group_by(block, time, type, dist) %>% summarize(HAvg = mean(value2))) %>% mutate(TempDiff = HAvg - UAvg)

mean.15min.depthavg <- flagged %>% filter(depth != 25, heatStat == "U", is.na(flag)) %>% group_by(block, time_15min) %>% summarize(UnheatedMean = mean(value)) %>% left_join(flagged %>% filter(depth != 25, heatStat == "H", is.na(flag)) %>% group_by(block, time_15min) %>% summarize(HeatedMean = mean(value))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

noband <- flagged %>% filter(is.na(band)) #why did some of these not calculate a sd, mean, band, value.5min, etc?

#transform from long to wide, with a value for each depth.  Incomplete cases will have NA for certain depths
# test.U <- flagged %>% filter(heatStat == "U", is.na(flag)) %>% select(block, time, heatStat, depth, dist, value) 
# 
# test.U[c(45527, 45528),]
# flagged %>% filter(time == "2016-07-24 22:19:39", heatStat == "U", depth == "5", dist == "10")

#%>% spread(depth, value)

#use na.omit to get rid of incomplete cases

#transform back to long format and summarize.

# # there w
# testframe <- data.frame(time = "2016-06-14 19:00:00", depth = 10)
# 
# testframe2 <- testframe %>% full_join(data.frame(depth = c(10, 15, 20, 25))) 
# 
# test.U <- flagged %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "U") %>% select(block, time, heatStat, depth) %>% full_join(data.frame(depth = c(10, 15, 20, 25))) 
# 
# test.H <- flagged %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "H") %>% select(block, time, heatStat, depth) %>% full_join(data.frame(depth = c(10, 15, 20, 25))) 
# 
# %>% bind_rows(flagged %>% filter(depth %in% c(10, 15, 20, 25), heatStat == "H") %>% select(block, time, heatStat, depth) %>% full_join(data.frame(depth = c(10, 15, 20, 25)))) %>% full_join (flagged) %>% mutate(value2 = ifelse(is.na(flag), value, NA)) 
# 
# test$value2 <- ifelse(is.na(test$flag), test$value, NA)
# 
# %>% group_by(block, time, heatStat)
# 
# test2 <- test %>% filter(block == "1", time == "2016-06-14 19:06:32")
# 
# 
# 
# #depths <- data.frame(depth = c(10, 15, 20, 25))
```

####Average the Uavg and Havg data every 15 minutes. 
```{r}
# UAvgHAvg.flagged$time_15min <- floor_datetime(UAvgHAvg.flagged$time, 15 * 60)
# 
# #calculate the average across all depths (10-25 cm) for evey 15-minute interval.  Include only measurements that haven't been flagged as outliers.
# flagged.15min.avg <- UAvgHAvg.flagged %>% group_by(block, type, time_15min) %>% summarize(UAvg_15min = mean(UAvg, na.rm=T), HAvg_15min = mean(HAvg, na.rm=T)) %>% mutate(TempDiff_15min = HAvg_15min - UAvg_15min)
# 
# #voltage.15min <- long %>% group_by(block, type, time_15min) %>% summarize(voltage = mean(Voltage))

```

####Save processed dataframes
```{r}
#temperatures averaged across all depths for every 15-minute interval, outliers ommitted
write.csv(mean.15min.depthavg, file = "data/2016_organized/flaggedBarrowFile.15min.avg_2016_4.csv") 

#voltageBarrow.15min_2016.csv (voltage averaged for each 15-min interval)
```

####remove this chunk after testing code above
####this code works for outlier detection (tested this before running as the for loop above)
```{r}
#isolate block 2, 5 cm depth, control board, heated, monitor, early measurements
plot <- "3"
cm <- "20"
MC <- "Ctl"
HU <- "H"
RM <- "M"

swap <- decoder %>% filter(block == plot, board_type == MC, start_date > "2016-01-01", interval == "5 minutes") %>% select(start_time)

early <- long %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, time <= swap[1])

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#first pass identifying outliers
#calculate the sd and mean over every 1-hour window
#if value is more than 2 sigma from the mean, flag it as an outlier
earlysd <- myrollapply(early$value, 120, sd)
earlymean <- myrollapply(early$value, 120, mean)
early[,"sd"] <- earlysd
early[,"mean"] <- earlymean
early$diff <- early$value - early$mean
early$band <- early$sd*3
early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
length(early[early$flag == "outlier"&!is.na(early$flag),]$flag)

outlierplot <- ggplot(early %>% filter(date == "2016-06-03"), aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)
```

####remove this chunk after testing code above
####Test for outlier detection
```{r}
longtest <- long %>% filter(block == 2) %>% filter(flag != "outlier") %>% filter(regStat == "R") %>% filter(time > "2016-09-14 00:00:00" & time < "2016-09-20 23:59:59")

testplot <- ggplot(longtest %>% filter(value <= 10 & value >= -10), aes(y = value, x = time, color = heatStat)) +
  geom_point(pch = 1) +
  facet_grid(depth~.) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") +
  scale_color_discrete(name = "Heater status", breaks = c("H", "U"), labels = c("Heated", "Unheated")) 
  
print(testplot + plottheme)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) ifelse (i < width/2 | length(vec) - i <width/2, NA, FUN(vec[(i-width/2):(i+width/2)], na.rm=T)))

#make a subset dataframe on which to do outlier detection
h5 <- longtest %>% filter(depth == "5") %>% filter(heatStat == "H")

#gap-fill the dataset so that there are observations every 5 minutes (fill with NA if no observation was recorded)
h5$min <- as.POSIXct(format(h5$time, "%Y-%m-%d %H:%M"))
z <- zoo(seq_along(h5$min), h5$min)
g <- zoo(, seq(start(z), end(z), 300))
zm <- merge(g, z)
h5 <- fortify.zoo(zm) %>% select("Index") %>% rename(min = Index) %>% full_join(h5)


#first pass identifying outliers
#calculate the sd and mean over every 4-hour time window
#if value is more than 2 sigma from the mean, flag it as an outlier
h5sd <- myrollapply(h5$value, 48, sd)
h5mean <- myrollapply(h5$value, 48, mean)
h5[,"sd"] <- h5sd
h5[,"mean"] <- h5mean
h5$diff <- h5$value - h5$mean
h5$band <- h5$sd*2
h5$flag <- NA
h5$flag <- ifelse(abs(h5$diff) > h5$band, "outlier", h5$flag)
length(h5[h5$flag == "outlier"&!is.na(h5$flag),]$flag)

outlierplot <- ggplot(h5, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") 
print(outlierplot + plottheme)

#second pass to flag remaining outliers
h5.2 <- h5 %>% filter(is.na(flag))
h5.2sd <- myrollapply(h5.2$value, 30, sd)
h5.2mean <- myrollapply(h5.2$value, 30, mean)
h5.2[,"sd"] <- h5.2sd
h5.2[,"mean"] <- h5.2mean
h5.2$diff <- h5.2$value - h5.2$mean
h5.2$band <- h5.2$sd*2.5
h5.2$flag <- NA
h5.2$flag <- ifelse(abs(h5.2$diff) > h5.2$band, "outlier", h5.2$flag)
length(h5.2[h5.2$flag == "outlier"&!is.na(h5.2$flag),]$flag)

outlierplot2 <- ggplot(h5.2, aes(y = value, x = time, color = flag)) +
  geom_point(pch = 1) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time")
print(outlierplot2 + plottheme)

h5 <- h5.2 %>% full_join(h5 %>% filter(flag == "outlier"))
```
