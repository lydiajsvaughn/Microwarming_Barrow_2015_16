---
title: "Microwarming data formatting 2016"
"
author: "Lydia Vaughn"
date: "22/05/2018"
output: html_document
---
#Description
```
This script reformats and processes data saved in line 249 of the "Barrow Data" script.  Processing includes outlier detection and recoding data with associated plot numbers.  The data originate from an field soil warming experiment in Barrow, Alaska.

Notes on column headers:
Uavg = the average of the regulator probes (regStat = "R") in the unheated plots (heatStat = "U") between depths of 10 and 25 cm (depth = c(10, 15, 20, 25))
```
#Code

##Install required packages

These packages only need to be installed once, then this code can be commented out or deleted.

Often, knitr does not like to install from the command window. If this is the case, look to the bottom right window and click on Packages -> Install -> and search for `knitr` in the window that opens.  

Knitr will provide a row of buttons across the top of the top left window in RStudio which allow you to view this document in html format (by clicking on the "Knit HTML" button), as well as run some or all of the code chunks below (by clicking on the "Chunks" button)

```{r}
#uncomment to install packages from command line
#install.packages("knitr")
#install.packages("zoo")
#install.packages("tidyverse")
#install.packages("lubridate")
```

####Read in files
```{r}
#complete 2016 dataset:
long <- read.csv('data/2016_organized/longBarrowFile_2016_4.csv', stringsAsFactors=F) 

decoder <- read.csv('data/control_box_decoder.csv', stringsAsFactors=F)

heatstat <- read.csv('data/HeaterStatus.csv', stringsAsFactors=F, na.strings = c(""))
```

####Packages
```{r}
library(tidyverse)
library(lubridate)
library(zoo)
```

####QA/QC full dataset
```{r}
unique(long$id)
#Drop the row if:

#1) If the value of id is not one of the strings listed in the decoder
long <- long %>% filter(id %in% unique(decoder$id))
#2) If a temperature probe value is 0.000
long <- long[long$value != 0.000,]
#3) If a HAvg or UAvg value is 0.000
#long <- long[long$HAvg != 0.000 & long$UAvg!= 0.000,]

#Query the remaining unique ids
unique(long$id)

#Figure out which of these ids have normal temperature values by asking for the summary for each id 
for (i in 1:length(unique(long$id))) {
  print(summary(long[long$id == unique(long$id)[i],]))
}  
```

####Format date and time on all dataframes
```{r}
long$time <- as.POSIXct(long$time)
long$date <- as.POSIXct(long$date, format = "%Y-%m-%d")

long <- long %>% filter(long$time > "2016-05-13" & !is.na(long$time))

decoder$start_date <- as.POSIXct(decoder$start_date, format = "%m/%d/%y")
decoder$end_date <- as.POSIXct(decoder$end_date, format = "%m/%d/%y")

heatstat$date <- as.POSIXct(heatstat$date, format = "%m/%d/%y")

decoder <- decoder %>% filter(decoder$start_date > "2016-01-01")

decoder$start_time <- paste(decoder$start_date, decoder$start_time)
decoder$end_time <- paste(decoder$end_date, decoder$end_time)

decoder$start_time <- as.POSIXct(decoder$start_time)
decoder$end_time <- as.POSIXct(decoder$end_time)
```

####Assign proper block and regStat to given control box id
```{r}
long$block <- "unknown"
long$type <- "unknown"

for(i in 1:length(decoder$id)){
  box <- decoder$id[i]
  block <- decoder$block[i]
  type <- decoder$board_type[i]
  starttime <- decoder$start_time[i]
  endtime <- decoder$end_time[i]
  
  long$block <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, block, long$block)
  
  long$type <- ifelse(long$id == box & long$time >= starttime & long$time <= endtime, type, long$type)
}
```

####Add variable for heater status (ON/OFF)
```{r}
#Convert heatstat from wide to long format
onoff <- heatstat %>% gather(key = "block", value = "heater", 3:6) %>% mutate(block = if_else(block == "b1", "1", if_else(block == "b2", "2", if_else(block == "b3", "3", "4"))))

#add heatstat variable to long dataframe
long <- long %>% left_join(onoff %>% select(date, block, heater))
```

###Make a dataframe of the dates heaters changed status
```{r}
onoff <- onoff %>% filter(date > "2016-01-01")

switch1 <- onoff %>% filter(block == 1) %>% select(block, date, heater) %>% mutate(heatSwitch = NA)

for(i in 2:length(switch1$heater)) {
  
  switch1[i,]$heatSwitch <- ifelse(switch1$heater[i] %in% c("ON", "ON*") & !(switch1$heater[i-1] %in% c("ON", "ON*")), "heat.start", NA)
  
  switch1[i-1,]$heatSwitch <- ifelse(switch1$heater[i-1] %in% c("ON", "ON*") & !(switch1$heater[i] %in% c("ON", "ON*")), "heat.end", switch1[i-1,]$heatSwitch)
  
}

switch2 <- onoff %>% filter(block == 2) %>% select(block, date, heater) %>% mutate(heatSwitch = NA)

for(i in 2:length(switch2$heater)) {
  
  switch2[i,]$heatSwitch <- ifelse(switch2$heater[i] %in% c("ON", "ON*") & !(switch2$heater[i-1] %in% c("ON", "ON*")), "heat.start", NA)
  
  switch2[i-1,]$heatSwitch <- ifelse(switch2$heater[i-1] %in% c("ON", "ON*") & !(switch2$heater[i] %in% c("ON", "ON*")), "heat.end", switch2[i-1,]$heatSwitch)
  
}

switch3 <- onoff %>% filter(block == 3) %>% select(block, date, heater) %>% mutate(heatSwitch = NA)

for(i in 2:length(switch3$heater)) {
  
  switch3[i,]$heatSwitch <- ifelse(switch3$heater[i] %in% c("ON", "ON*") & !(switch3$heater[i-1] %in% c("ON", "ON*")), "heat.start", NA)
  
  switch3[i-1,]$heatSwitch <- ifelse(switch3$heater[i-1] %in% c("ON", "ON*") & !(switch3$heater[i] %in% c("ON", "ON*")), "heat.end", switch3[i-1,]$heatSwitch)
  
}


switch4 <- onoff %>% filter(block == 4) %>% select(block, date, heater) %>% mutate(heatSwitch = NA)

for(i in 2:length(switch4$heater)) {
  
  switch4[i,]$heatSwitch <- ifelse(switch4$heater[i] %in% c("ON", "ON*") & !(switch4$heater[i-1] %in% c("ON", "ON*")), "heat.start", NA)
  
  switch4[i-1,]$heatSwitch <- ifelse(switch4$heater[i-1] %in% c("ON", "ON*") & !(switch4$heater[i] %in% c("ON", "ON*")), "heat.end", switch4[i-1,]$heatSwitch)
  
}
  
heat.switch <- switch1 %>% full_join(switch2) %>% full_join(switch3) %>% full_join(switch4) %>% filter(!is.na(heatSwitch)) %>% select(-heater) %>% rename("time" = "date")

write.csv(heat.switch, file = "data/2016_organized/heaterSwitch_2016.csv") 
```

####Clean 2016 data, based on when I know probes were faulty or mislabeled
#run this chunk only for 2016 data
```{r}
#U and H were swapped for the following traces:
#Block 1 from 6/14/16 until 10/14/16, regulator probes, starting a ~19:00 except for the 35 and 50 cm depths.  
#Block 4, dist = 8, before 2016-05-25 

long <- long %>% full_join(long %>% filter(id == "89A1" & time >= "2016-06-14 18:02:30" & time <= "2016-10-14 14:49:38" & regStat == "R") %>% full_join(long %>% filter(id == "B7D1" & time >= "2016-06-14 19:01:28" & time <= "2016-10-14 14:46:40" & regStat == "R")) %>% mutate(UH.swap = "yes")) %>% full_join(long %>% filter(block == 4, dist == 8, time < "2016-05-25") %>% mutate(UH.swap = "yes"))

long <- long %>% filter(is.na(UH.swap)) %>% full_join(long %>% filter(!is.na(UH.swap)) %>% mutate(heatStat = if_else(heatStat == "U", "H", "U"))) %>% select(-UH.swap)

#Create a variable for flagging bad data
long <- long %>% mutate(flag = NA)

#Flag the following bad traces:
#Block 1, Monitor, dist = 10, depth = 20, heatStat = U
#Block 2, Monitor, dist = 8
#Block 2, Monitor, dist = 6, heatStat = H
#Block 3, Ctl, dist = 8, depth = 25, heatStat = H
#Block 3, Ctl, dist = 6, depth = 20
#Block 4, Monitor, dist = 10, depth = 50, heatStat = H
#Block 4, Ctl, dist = 8, depth = 5, heatStat = H, date > 2016-06-01
long <- long %>% mutate(flag = ifelse(date > "2016-01-01" & block == "1" & type == "Monitor" & dist == "10" & depth == "20" & heatStat == "U", "badProbe", ifelse(date > "2016-01-01" & block == "2" & type == "Monitor" & dist == "8", "badProbe", ifelse(date > "2016-01-01" & block == "2" & type == "Monitor" & dist == "6" & heatStat == "H", "badProbe", ifelse(date > "2016-01-01" & block == "3" & type == "Ctl" & dist == "8" & depth == "25" & heatStat == "H", "badProbe", ifelse(date > "2016-01-01" & block == "3" & type == "Ctl" & dist == "6" & depth == "20", "badProbe", ifelse(date > "2016-01-01" & block == "4" & type == "Monitor" & dist == "10" & depth == "50" & heatStat == "H", "badProbe", ifelse(block == "4" & type == "Ctl" & dist == "8" & depth == "5" & heatStat == "H" & date > "2016-06-01", "badTrace", flag))))))))

#flag all measurements that are wildly too high or too low
long <- long %>% mutate(flag = if_else(value >= 20 & is.na(flag), "outlier", if_else(value <= -5 & is.na(flag), "outlier", flag)))

#additional bad traces or heater ramp-up periods detected during data cleaning

#flag the ramp-up period in block 4 following a heater outage.  (This should not be included in across-block averages of the heater effect)
long <- long %>% mutate(flag = if_else(block == 4 & date >= "2016-06-07" & date <= "2016-06-11" & is.na(flag), "ramp-up", flag))

#flag the little heater outage in block 4 immediately after the previous ramp-up
long <- long %>% mutate(flag = if_else(block == 4 & time >= "2016-06-12 18:00:00" & time <= "2016-06-13 18:00:00" & is.na(flag), "ramp-up", flag))

#flag the ramp-up period in block 1 following the heater outage that ended on July 21.
long <- long %>% mutate(flag = if_else(block == 1 & date >= "2016-07-22" & date <= "2016-07-23" & is.na(flag), "ramp-up", flag))

#flag the heater outage overnight on June 8/9
long <- long %>% mutate(flag = if_else(block == 1 & time >= "2016-06-07 12:00:00" & date <= "2016-06-10" & is.na(flag), "ramp-up", flag))

#flag the ramp-up period in block 1 after heaters were turned on in October
long <- long %>% mutate(flag = if_else(block == 1 & date >= "2016-10-11" & is.na(flag), "ramp-up", flag))

#flag the initial ramp-up period when heaters were turned on in
long <- long %>% mutate(flag = if_else(date < "2016-05-25" & is.na(flag), "ramp-up", flag))

```

####Data were recorded at 30-second intervals until mid-June, then at 5-minute intervals for the rest of the season.  Break the dataset into 30-second and 5-minute groups.
```{r}
early1 <- long %>% filter(block == 1, type == "Ctl", time < first(decoder %>% filter(block == 1, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 1, type == "Monitor", time < first(decoder %>% filter(block == 1, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

early2 <- long %>% filter(block == 2, type == "Ctl", time < first(decoder %>% filter(block == 2, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 2, type == "Monitor", time < first(decoder %>% filter(block == 2, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

early3 <- long %>% filter(block == 3, type == "Ctl", time < first(decoder %>% filter(block == 3, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 3, type == "Monitor", time < first(decoder %>% filter(block == 3, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

early4 <- long %>% filter(block == 4, type == "Ctl", time < first(decoder %>% filter(block == 4, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 4, type == "Monitor", time < first(decoder %>% filter(block == 4, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

early.all <- rbind(early1, early2, early3, early4) %>% filter(!is.na(time))

rm(early1, early2, early3, early4)
  
late1 <- long %>% filter(block == 1, type == "Ctl", time >= first(decoder %>% filter(block == 1, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 1, type == "Monitor", time >= first(decoder %>% filter(block == 1, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

late2 <- long %>% filter(block == 2, type == "Ctl", time >= first(decoder %>% filter(block == 2, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 2, type == "Monitor", time >= first(decoder %>% filter(block == 2, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

late3 <- long %>% filter(block == 3, type == "Ctl", time >= first(decoder %>% filter(block == 3, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 3, type == "Monitor", time >= first(decoder %>% filter(block == 3, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

late4 <- long %>% filter(block == 4, type == "Ctl", time >= first(decoder %>% filter(block == 4, board_type == "Ctl", interval == "5 minutes") %>% select(start_time))) %>% full_join(long %>% filter(block == 4, type == "Monitor", time >= first(decoder %>% filter(block == 4, board_type == "Monitor", interval == "5 minutes") %>% select(start_time))))

late.all <- rbind(late1, late2, late3, late4) %>% filter(!is.na(time))

rm(late1, late2, late3, late4)

rm(long) #do this only if needed to clear up memory
```

####Flag outliers on all time series recorded at 30 second intervals
####calculate the sd and mean over every 1-hour window
####if value is more than 2 sigma from the mean, flag it as an outlier
```{r}
flagged.early <- early.all[0:0,]
depths <- unique(early.all$depth)
board_type <- unique(early.all$type)
heatStat <- unique(early.all$heatStat)
regStat <- unique(early.all$regStat)
dist <- unique(early.all$dist)

#function to calculate mean and sd for a rolling window
myrollapply <- function(vec, width, FUN) 
    sapply(seq_along(vec), 
           function(i) FUN(vec[(i-min(i, width/2)):(i+width/2)], na.rm=T))

combinations <- early.all %>% select(block, depth, type, heatStat, regStat, dist) %>% distinct()

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  early <- early.all %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance) %>% filter(is.na(flag) | flag == "ramp-up")  #isolate a given trace, minus values that were already flagged as bad data (all flags except "ramp-up")

#To define a 1-hour rolling window, gap-fill missing values in the dataset with NA rows every 30 seconds.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 30-second window (because while they are recorded approximately every 30 seconds, the clock occasionally shifts by a second or two).
  early$timestamp <- floor_date(early$time, "0.5 mins")

#(2) Gap-fill the dataset so there is a row every 30 seconds.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(early$timestamp)) == 0, early, data.frame(timestamp =seq(min(early$timestamp), max(early$timestamp), 30)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(early$timestamp)) == 0) {early$timestamp <- as.integer(early$timestamp)} 

  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 

  early <- timestamps %>% full_join(early) %>% arrange(timestamp)
  
  earlysd <- myrollapply(early$value, 120, sd)
  earlymean <- myrollapply(early$value, 120, mean)
  early[,"sd"] <- earlysd
  early[,"mean"] <- earlymean
  early$diff <- early$value - early$mean
  early$band <- early$sd*2
  early$flag <- ifelse(abs(early$diff) > early$band, "outlier", early$flag)
          
  flagged.early <- rbind(flagged.early, early)

}


#Assign outlier status to all values that are alone within the rolling window
flagged.early <- flagged.early %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit gap-filled timestamps
flagged.early <- flagged.early %>% filter(!is.na(value))

#add back in rows that were previously flagged
flagged.early <- early.all %>% filter(!is.na(flag), flag != "ramp-up") %>% full_join(flagged.early)

```

####Flag outliers on all time series recorded at 5 minute intervals
####use 4-hour rolling window
```{r}
flagged.late <- late.all[0:0,]

for(i in 1:length(combinations$block)) {
  plot <- combinations$block[i]
  cm <- combinations$depth[i]
  MC <- combinations$type[i]
  HU <- combinations$heatStat[i]
  RM <- combinations$regStat[i]
  distance <- combinations$dist[i]
  
  late <- late.all %>% filter(block == plot, depth == cm, type == MC, heatStat == HU, regStat == RM, dist == distance) %>% filter(is.na(flag) | flag == "ramp-up")  #isolate a given trace, minus values that were already flagged as bad data (all flags except "ramp-up")


#In order to select a 4-hour rolling window, gap-fill the dataset so that is a row for every 5-minute time interval.  This deals with the issue of missing values in the dataset by adding NA rows for these missing values, with an appropriate time stamp.  This method is more efficient than searching for a date range with myrollapply (as in myrollapply.2). 

#(1) Assign each measurement to the beginning of a 5-minute window (because while they are recorded approximately every 5 minutes, the clock occasionally shifts by a second or two).
  late$timestamp <- floor_date(late$time, "5 mins")

#(2) To make sure there is exactly one measurement every 5 minutes, compute a 5-minute average
  mean.5min <- late %>% group_by(timestamp, flag) %>% summarize(value.5min = mean(value, na.rm = T))

#(3) Gap-fill the dataset so there is a row every 5 minutes.  
  timestamps <- data.frame(timestamp = ifelse(length(!is.na(mean.5min$timestamp)) == 0, mean.5min, data.frame(timestamp =seq(min(mean.5min$timestamp), max(mean.5min$timestamp), 300)))) 
  
  colnames(timestamps) = c("timestamp")
  
  if(length(is.na(mean.5min$timestamp)) == 0) {mean.5min$timestamp <- as.integer(mean.5min$timestamp)} 
  
  if(length(is.na(timestamps$timestamp)) == 0) {timestamps$timestamp <- as.integer(timestamps$timestamp)} 
  
  mean.5min <- timestamps %>% full_join(mean.5min) %>% arrange(timestamp)
          
  latesd <- myrollapply(mean.5min$value.5min, 48, sd)
  latemean <- myrollapply(mean.5min$value.5min, 48, mean)
  mean.5min[,"sd"] <- latesd
  mean.5min[,"mean"] <- latemean
  mean.5min$diff <- mean.5min$value.5min - mean.5min$mean
  mean.5min$band <- mean.5min$sd*2
  
  mean.5min$flag <- ifelse(abs(mean.5min$diff) > mean.5min$band, "outlier", mean.5min$flag)
               
  if(length(is.na(late$timestamp)) == 0) {late$timestamp <- as.integer(late$timestamp)} 

  late <- mean.5min %>% mutate(flag = as.character(flag)) %>% full_join(late %>% select(-flag))
  
  flagged.late <- flagged.late %>% bind_rows(late)

}

#Assign outlier status to all values that are alone within the rolling window
flagged.late <- flagged.late %>% mutate(flag = if_else(diff == 0.0000, "outlier", flag))

#Omit gap-filled timestamps
flagged.late <- flagged.late %>% filter(!is.na(value))

#add back in rows that were previously flagged
flagged.late <- late.all %>% filter(!is.na(flag), flag != "ramp-up") %>% full_join(flagged.late)

flagged <- flagged.late %>% bind_rows(flagged.early)

rm(flagged.late, flagged.early, early.all, late.all) #to free up memory
gc()
```

Save flagged dataframe (the original dataset plus outlier flags)
```{r}
write.csv(flagged, file = "data/2016_organized/flaggedBarrowFile_2016_7.csv") 
```

####Optional: read in flagged file and format time variable
```{r}
#flagged <- read.csv('data/2016_organized/flaggedBarrowFile_2016_7.csv', stringsAsFactors=F)

#flagged$time <- as.POSIXct(flagged$time)
```

####To visualize outliers
```{r}
plottheme <- theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) +
  theme(axis.text.y = element_text(color="black", size=12)) +
  theme(axis.text.x = element_text(color="black", size=12, angle=90, vjust=.5)) +
  theme(axis.title.y = element_text(size=14)) +
  theme(axis.title.x = element_blank()) +
  theme(legend.position = c(.9, .85)) +
  theme(legend.title = element_text(size=14)) +
  theme(legend.text = element_text(size=12))

outliers <- flagged %>% filter(date == "2016-06-07", block == 1, heatStat == "H") #modify filter criteria to explore other dates/blocks

outlierplot <- ggplot(outliers, aes(y = value, x = time)) +
  geom_point(pch = 1, aes(color = flag)) +
  ylab(expression("Temperature" ~ (degree * C))) +
  xlab("Time") +
  facet_grid(depth~dist)
print(outlierplot + plottheme)
```

####Average every 15 minutes. 
```{r}
  floor_datetime <- function(date_var, floor_seconds = 60, 
        origin = "1970-01-01") { # defaults to minute rounding
     if(!is(date_var, "POSIXct")) stop("Please pass in a POSIXct variable")
     if(is.na(date_var)) return(as.POSIXct(NA)) else {
        return(as.POSIXct(floor(as.numeric(date_var) / 
           (floor_seconds))*(floor_seconds), origin = origin))
     }
  }

flagged$time_15min <- floor_datetime(flagged$time, 15 * 60)

#flagged <- flagged %>% mutate(flag = ifelse(flag == "NA", NA, flag))

#calculate the average for each plot and depth for each 15-minute interval
mean.15min <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, block, time_15min, heatStat, depth, heater, flag) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 15-minute interval
mean.15min.probe <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, block, time_15min, heatStat, depth, regStat, dist, type, heater, flag) %>% summarize(temp = mean(value)) 

mean.15min.dist <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_15min, heatStat, depth, dist, flag) %>% summarize(temp = mean(value)) 

```

####Average every hour
```{r}
flagged$time_hour <- floor_datetime(flagged$time, 60 * 60)

#calculate the average for each plot and depth for each 1-hour interval
mean.hour <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_hour, heatStat, depth, flag) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 1-hour interval
mean.hour.probe <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_hour, heatStat, depth, regStat, dist, type, flag) %>% summarize(temp = mean(value)) 

mean.hour.dist <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_hour, heatStat, depth, dist, flag) %>% summarize(temp = mean(value)) 

```

####Average every 4 hours
```{r}
#flagged$time_4hour <- floor_datetime(flagged$time, 240 * 60)
flagged$time_4hour <- floor_date(flagged$time, "4 hour")

#calculate the average for each plot and depth for each 4-hour interval
mean.4hour <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_4hour, heatStat, depth, flag) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 4-hour interval
mean.4hour.probe <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_4hour, heatStat, depth, regStat, dist, type, flag) %>% summarize(temp = mean(value)) 

mean.4hour.dist <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_4hour, heatStat, depth, dist, flag) %>% summarize(temp = mean(value)) 

```

####Average every 6 hours
```{r}
#flagged$time_6hour <- floor_datetime(flagged$time, 360 * 60)
flagged$time_6hour <- floor_date(flagged$time, "6 hour")

#calculate the average for each plot and depth for each 6-hour interval
mean.6hour <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_6hour, heatStat, depth, flag) %>% summarize(temp = mean(value)) 

#calculate the average for each probe for each 6-hour interval
mean.6hour.probe <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_6hour, heatStat, depth, regStat, dist, type, flag) %>% summarize(temp = mean(value)) 

mean.6hour.dist <- flagged %>% filter(is.na(flag) | flag == "ramp-up") %>% group_by(date, heater, block, time_6hour, heatStat, depth, dist, flag) %>% summarize(temp = mean(value)) 

```

####Write to csv files
```{r}
#temperatures averaged for each plot and depth for every 15-min interval, outliers omitted
write.csv(mean.15min, file = "data/2016_organized/flaggedBarrowFile.15min_2016_7.csv") 

#temperatures averaged for each probe, every 15-min interval, outliers omitted
write.csv(mean.15min.probe, file = "data/2016_organized/flaggedBarrowFile.15min.probe_2016_7")

#temperatures averaged for each distance from the plot center, every 15-min interval, outliers omitted
write.csv(mean.15min.dist, file = "data/2016_organized/flaggedBarrowFile.15min.dist_2016_7")

#temperatures averaged for each plot and depth for every 1-hour interval, outliers omitted
write.csv(mean.hour, file = "data/2016_organized/flaggedBarrowFile.1hour_2016_7.csv") 

#temperatures averaged for each probe, every 1-hour interval, outliers omitted
write.csv(mean.hour.probe, file = "data/2016_organized/flaggedBarrowFile.1hour.probe_2016_7")

#temperatures averaged for each distance from the plot center, every 1-hour interval, outliers omitted
write.csv(mean.hour.dist, file = "data/2016_organized/flaggedBarrowFile.1hour.dist_2016_7")

#temperatures averaged for each plot and depth for every 4-hour interval, outliers omitted
write.csv(mean.4hour, file = "data/2016_organized/flaggedBarrowFile.4hour_2016_7.csv") 

#temperatures averaged for each probe, every 4-hour interval, outliers omitted
write.csv(mean.4hour.probe, file = "data/2016_organized/flaggedBarrowFile.4hour.probe_2016_7")

#temperatures averaged for each distance from the plot center, every 4-hour interval, outliers omitted
write.csv(mean.4hour.dist, file = "data/2016_organized/flaggedBarrowFile.4hour.dist_2016_7")

#temperatures averaged for each plot and depth for every 6-hour interval, outliers omitted
write.csv(mean.6hour, file = "data/2016_organized/flaggedBarrowFile.6hour_2016_7.csv") 

#temperatures averaged for each probe, every 6-hour interval, outliers omitted
write.csv(mean.6hour.probe, file = "data/2016_organized/flaggedBarrowFile.6hour.probe_2016_7")

#temperatures averaged for each distance from the plot center, every 6-hour interval, outliers omitted
write.csv(mean.6hour.dist, file = "data/2016_organized/flaggedBarrowFile.6hour.dist_2016_7")
```

####Calculate the depth-averaged temperatures in each plot for each 15-minute, 1-hour, 4-hour, and 6-hour time period.  Also calculate the difference between the heated and unheated plot for each block.  Do not use depth == 25, since it is missing from most (but not all) data streams.  Also do not use depth == 15, because it is missing from a large chunk of block 1 and 2.    Use only complete cases (i.e., where data exist for all non-15cm and non-25cm depths).  
####Also calculate the mean heating effect (H-U) when heaters are on, averaged across depths and blocks
```{r}
#15-min average
mean.15min <-mean.15min %>% full_join(mean.15min %>% filter(depth != 25 & depth != 15) %>% group_by(time_15min, block, heatStat, flag) %>% summarize(depths = length(depth))) 

mean.15min.depthavg <- mean.15min %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(date, heater, block, time_15min, flag) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.15min %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(date, heater, block, time_15min, flag) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

mean.15min.depthavg$block <- as.character(mean.15min.depthavg$block)

mean.15min.depthavg <- mean.15min.depthavg %>% full_join(mean.15min.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(n = length(time_hour)) %>% full_join(mean.15min.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(TempDiff = mean(TempDiff))) %>% mutate(heater = "ON", block = "all"))

#1-hour average
mean.hour <-mean.hour %>% full_join(mean.hour %>% filter(depth != 25, depth != 15) %>% group_by(time_hour, block, heatStat, flag) %>% summarize(depths = length(depth))) 

mean.hour.depthavg <- mean.hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(date, heater, block, time_hour, flag) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(date, heater, block, time_hour, flag) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

mean.hour.depthavg$block <- as.character(mean.hour.depthavg$block)

mean.hour.depthavg <- mean.hour.depthavg %>% full_join(mean.hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(n = length(time_hour)) %>% full_join(mean.hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(TempDiff = mean(TempDiff))) %>% mutate(heater = "ON", block = "all"))

#1-hour average without the 50 cm and 5 cm depths
mean.hour.depthavg.lim <- mean.hour %>% filter(depth != 25, depth != 15, depth != 5, depth != 50, depths == 5, heatStat == "U") %>% group_by(date, heater, block, time_hour, flag) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.hour %>% filter(depth != 25, depth != 15, depth != 50, depth != 5, depths == 5, heatStat == "H") %>% group_by(date, heater, block, time_hour, flag) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

mean.hour.depthavg.lim <- mean.hour.depthavg.lim %>% full_join(mean.hour.depthavg.lim %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(n = length(time_hour)) %>% full_join(mean.hour.depthavg.lim %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(TempDiff = mean(TempDiff))) %>% mutate(heater = "ON", block = "all"))

#4-hour average
mean.4hour <-mean.4hour %>% full_join(mean.4hour %>% filter(depth != 25, depth != 15) %>% group_by(time_4hour, block, heatStat, flag) %>% summarize(depths = length(depth))) 

mean.4hour.depthavg <- mean.4hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(date, heater, block, time_4hour, flag) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.4hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(date, heater, block, time_4hour, flag) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

mean.4hour.depthavg$block <- as.character(mean.4hour.depthavg$block)

mean.4hour.depthavg <- mean.4hour.depthavg %>% full_join(mean.4hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(n = length(time_hour)) %>% full_join(mean.4hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(TempDiff = mean(TempDiff))) %>% mutate(heater = "ON", block = "all"))

#6-hour average
mean.6hour <-mean.6hour %>% full_join(mean.6hour %>% filter(depth != 25, depth != 15) %>% group_by(time_6hour, block, heatStat, flag) %>% summarize(depths = length(depth))) 

mean.6hour.depthavg <- mean.6hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "U") %>% group_by(date, heater, block, time_6hour, flag) %>% summarize(UnheatedMean = mean(temp)) %>% left_join(mean.6hour %>% filter(depth != 25, depth != 15, depths == 5, heatStat == "H") %>% group_by(date, heater, block, time_6hour, flag) %>% summarize(HeatedMean = mean(temp))) %>% mutate(TempDiff = HeatedMean - UnheatedMean)

mean.6hour.depthavg$block <- as.character(mean.6hour.depthavg$block)

mean.6hour.depthavg <- mean.6hour.depthavg %>% full_join(mean.6hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(n = length(time_hour)) %>% full_join(mean.6hour.depthavg %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% group_by(time_hour) %>% summarize(TempDiff = mean(TempDiff))) %>% mutate(heater = "ON", block = "all"))
```

####Save processed dataframes
```{r}
#temperatures averaged across all depths for every 15-minute interval, outliers ommitted
write.csv(mean.15min.depthavg, file = "data/2016_organized/flaggedBarrowFile.15min.avg_2016_7.csv") 

write.csv(mean.hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.1hour.avg_2016_7.csv") 

write.csv(mean.hour.depthavg.lim, file = "data/2016_organized/flaggedBarrowFile.1hour.avg.lim_2016_7.csv") 

write.csv(mean.4hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.4hour.avg_2016_7.csv") 

write.csv(mean.6hour.depthavg, file = "data/2016_organized/flaggedBarrowFile.6hour.avg_2016_7.csv") 

#voltageBarrow.15min_2016.csv (voltage averaged for each 15-min interval)
```

####Calculate average heating effect (H-U) across plots for each depth, only when heaters are on and not during the ramp-up period following a heater outage.
```{r}
mean.15min.blockavg <- mean.15min %>% select(-depths) %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff)) %>% group_by(time_15min, depth) %>% summarize(mean.TempDiff = mean(TempDiff), sd = sd(TempDiff), n = length(depth), se = sd / n^0.5)

mean.hour.blockavg <- mean.hour %>% select(-depths) %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff)) %>% group_by(time_hour, depth) %>% summarize(mean.TempDiff = mean(TempDiff), sd = sd(TempDiff), n = length(depth), se = sd / n^0.5)

mean.4hour.blockavg <- mean.4hour %>% select(-depths) %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff)) %>% group_by(time_4hour, depth) %>% summarize(mean.TempDiff = mean(TempDiff), sd = sd(TempDiff), n = length(depth), se = sd / n^0.5)

mean.6hour.blockavg <- mean.6hour %>% select(-depths) %>% filter(heater %in% c("ON", "ON*"), is.na(flag)) %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff)) %>% group_by(time_6hour, depth) %>% summarize(mean.TempDiff = mean(TempDiff), sd = sd(TempDiff), n = length(depth), se = sd / n^0.5)
```

####Save processed dataframes
```{r}
#temperatures averaged across all depths for every 15-minute interval, outliers ommitted
write.csv(mean.15min.blockavg, file = "data/2016_organized/flaggedBarrowFile.15min.blocks_2016_7.csv") 

write.csv(mean.hour.blockavg, file = "data/2016_organized/flaggedBarrowFile.1hour.blocks_2016_7.csv") 

write.csv(mean.4hour.blockavg, file = "data/2016_organized/flaggedBarrowFile.4hour.blocks_2016_7.csv") 

write.csv(mean.6hour.blockavg, file = "data/2016_organized/flaggedBarrowFile.6hour.blocks_2016_7.csv") 
```

####Calculate the heating effect for each block, for each depth
```{r}
#1-hour averages
mean.hour.tdiff <- mean.hour %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U)

write.csv(mean.hour.tdiff, file = "data/2016_organized/flaggedBarrowFile.1hour.Tdiff_2016_7.csv") 
```

####Compute the range in temperatures across the 3 distances, calculated separately for each depth and block
####Limit to instances where both 6 and 10 cm distances are measured (only 5, 10, and 20 cm depth)
```{r}
ranges <- mean.hour.dist %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff)) %>% group_by(heater, block, time_hour, depth, flag) %>% summarize(min.Tdiff = min(range(TempDiff)), max.Tdiff = max(range(TempDiff)), n_6.8.10 = length(TempDiff)) %>% right_join(mean.hour.dist %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(!is.na(TempDiff), dist != 8) %>% group_by(heater, block, time_hour, depth, flag) %>% summarize(n_6.10 = length(TempDiff)) %>% filter(n_6.10 == 2)) %>% left_join(mean.hour.dist %>% spread(key = heatStat, value = temp) %>% mutate(TempDiff = H - U) %>% filter(dist == 8) %>% select(heater, block, time_hour, depth, TempDiff) %>% rename("TempDiff.8cm" = "TempDiff"))

write.csv(ranges, file = "data/2016_organized/flaggedBarrowFile.1hour.range_2016_7.csv")
```